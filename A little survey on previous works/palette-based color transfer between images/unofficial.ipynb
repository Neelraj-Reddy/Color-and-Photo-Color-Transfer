{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelraj-reddy/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/neelraj-reddy/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# ---------------------- 1. Load Mask R-CNN Model ----------------------\n",
    "def load_mask_rcnn():\n",
    "    \"\"\"Loads pre-trained Mask R-CNN model.\"\"\"\n",
    "    model = models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "load_mask_rcnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------- 2. Foreground-Background Segmentation ----------------------\n",
    "def segment_foreground_background(image, model, threshold=0.5):\n",
    "    \"\"\"Returns a binary mask for foreground segmentation using Mask R-CNN.\"\"\"\n",
    "    transform = T.Compose([T.ToPILImage(), T.ToTensor()])\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor)[0]\n",
    "\n",
    "    # Get the mask with highest score (most confident detection)\n",
    "    if len(predictions['masks']) > 0:\n",
    "        best_mask_idx = torch.argmax(predictions['scores']).item()\n",
    "        mask = predictions['masks'][best_mask_idx, 0].byte().cpu().numpy()\n",
    "    else:\n",
    "        # Return a zero mask if no object is detected\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    # Binarize mask: 1 for foreground, 0 for background\n",
    "    return (mask > threshold).astype(np.uint8)\n",
    "\n",
    "# ---------------------- 3. Palette-based Clustering ----------------------\n",
    "def generate_palette(image_lab, bins=100, max_colors=32, threshold=30, radius=3):\n",
    "    \"\"\"Generates a color palette using histogram analysis in Lab space.\"\"\"\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "    \n",
    "    # Construct histograms\n",
    "    hist_l = np.histogram(l_channel, bins=bins, range=[0, 255])[0]\n",
    "    hist_a = np.histogram(a_channel, bins=bins, range=[0, 255])[0]\n",
    "    hist_b = np.histogram(b_channel, bins=bins, range=[0, 255])[0]\n",
    "\n",
    "\n",
    "    # Detect peaks in histograms\n",
    "    peaks_l = peak_search(hist_l, threshold, radius)\n",
    "    peaks_a = peak_search(hist_a, threshold, radius)\n",
    "    peaks_b = peak_search(hist_b, threshold, radius)\n",
    "\n",
    "    # Combine peaks to form initial palette\n",
    "    raw_palette = np.array([[l, a, b] for l in peaks_l for a in peaks_a for b in peaks_b], dtype=np.float32)\n",
    "\n",
    "    # Merge close peaks and reduce size\n",
    "    final_palette = merge_peaks(raw_palette, max_colors)\n",
    "    return final_palette\n",
    "\n",
    "def peak_search(hist, threshold, radius):\n",
    "    \"\"\"Finds peaks in a histogram.\"\"\"\n",
    "    peaks = []\n",
    "    for i in range(radius, len(hist) - radius):\n",
    "        if hist[i] > threshold and hist[i] == max(hist[i - radius:i + radius + 1]):\n",
    "            peaks.append(i)\n",
    "    return peaks if peaks else [0, 255]  # Include boundary values if no peaks\n",
    "\n",
    "def merge_peaks(raw_palette, max_colors):\n",
    "    \"\"\"Merges close peaks to reduce palette size.\"\"\"\n",
    "    if len(raw_palette) <= max_colors:\n",
    "        return raw_palette\n",
    "\n",
    "    tree = KDTree(raw_palette)\n",
    "    merged_palette = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, color in enumerate(raw_palette):\n",
    "        if i not in used:\n",
    "            neighbors = tree.query_radius([color], r=10)[0]\n",
    "            mean_color = np.mean([raw_palette[j] for j in neighbors], axis=0)\n",
    "            merged_palette.append(mean_color)\n",
    "            used.update(neighbors)\n",
    "        \n",
    "        # Stop when max_colors is reached\n",
    "        if len(merged_palette) >= max_colors:\n",
    "            break\n",
    "\n",
    "    return np.array(merged_palette[:max_colors], dtype=np.float32)\n",
    "\n",
    "# ---------------------- 4. Color Mapping Strategy ----------------------\n",
    "def transfer_colors(source_lab, reference_lab, source_palette, reference_palette, mask):\n",
    "    \"\"\"Performs color transfer with split correspondence, chromatic aberration, and consistency keeping.\"\"\"\n",
    "    tree = KDTree(reference_palette)\n",
    "\n",
    "    # Separate foreground and background\n",
    "    fg_indices = np.where(mask == 1)\n",
    "    bg_indices = np.where(mask == 0)\n",
    "\n",
    "    # Foreground mapping\n",
    "    if len(fg_indices[0]) > 0:\n",
    "        transfer_foreground(source_lab, reference_lab, source_palette, reference_palette, fg_indices, tree)\n",
    "\n",
    "    # Background mapping\n",
    "    if len(bg_indices[0]) > 0:\n",
    "        transfer_foreground(source_lab, reference_lab, source_palette, reference_palette, bg_indices, tree)\n",
    "\n",
    "    return source_lab\n",
    "\n",
    "def transfer_foreground(source_lab, reference_lab, source_palette, reference_palette, indices, tree):\n",
    "    \"\"\"Transfers colors for foreground or background pixels.\"\"\"\n",
    "    h, w, _ = source_lab.shape\n",
    "    \n",
    "    for i, j in zip(indices[0], indices[1]):\n",
    "        # Boundary check to prevent out-of-bounds error\n",
    "        if i >= h or j >= w:\n",
    "            continue\n",
    "        \n",
    "        pixel = source_lab[i, j]\n",
    "        _, idx = tree.query([pixel], k=1)\n",
    "        \n",
    "        # Ensure the index is valid\n",
    "        if 0 <= idx[0][0] < len(reference_palette):\n",
    "            source_lab[i, j] = reference_palette[idx[0][0]]\n",
    "\n",
    "# ---------------------- 5. Internal and External Consistency ----------------------\n",
    "def maintain_consistency(source_lab, reference_lab, source_palette, reference_palette):\n",
    "    \"\"\"Maintains color consistency and chromatic aberration control.\"\"\"\n",
    "    mapping = {}\n",
    "    for src, ref in zip(source_palette, reference_palette):\n",
    "        if tuple(src) not in mapping:\n",
    "            mapping[tuple(src)] = ref\n",
    "        else:\n",
    "            mapping[tuple(src)] = 0.5 * (mapping[tuple(src)] + ref)\n",
    "\n",
    "    for i in range(source_lab.shape[0]):\n",
    "        for j in range(source_lab.shape[1]):\n",
    "            pixel = tuple(source_lab[i, j])\n",
    "            if pixel in mapping:\n",
    "                source_lab[i, j] = mapping[pixel]\n",
    "    return source_lab\n",
    "\n",
    "# ---------------------- 6. Lighting Optimization ----------------------\n",
    "def optimize_lighting(transferred_lab, reference_lab, alpha=0.3):\n",
    "    \"\"\"Applies lighting optimization to prevent abnormal exposure.\"\"\"\n",
    "    h, w, _ = transferred_lab.shape\n",
    "\n",
    "    # Resize reference_lab to match transferred_lab dimensions\n",
    "    reference_lab_resized = cv2.resize(reference_lab, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    l_channel_src, a_channel_src, b_channel_src = cv2.split(transferred_lab)\n",
    "    l_channel_ref = reference_lab_resized[:, :, 0]\n",
    "\n",
    "    # Weighted update of L-channel\n",
    "    l_channel_optimized = (1 - alpha) * l_channel_src + alpha * l_channel_ref\n",
    "\n",
    "    # Convert to uint8 before merging\n",
    "    l_channel_optimized = np.clip(l_channel_optimized, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Merge channels to form the optimized Lab image\n",
    "    optimized_lab = cv2.merge([l_channel_optimized, a_channel_src, b_channel_src])\n",
    "\n",
    "    # Optional global lighting enhancement\n",
    "    optimized_lab = enhance_global_lighting(optimized_lab)\n",
    "    return optimized_lab\n",
    "\n",
    "def enhance_global_lighting(image_lab):\n",
    "    \"\"\"Enhances global lighting using histogram stretching.\"\"\"\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "    \n",
    "    # Equalize histogram for L-channel to enhance brightness\n",
    "    l_channel = cv2.equalizeHist(l_channel.astype(np.uint8))\n",
    "    \n",
    "    # Merge the enhanced L-channel with original A and B channels\n",
    "    return cv2.merge([l_channel, a_channel, b_channel])\n",
    "\n",
    "# ---------------------- 7. Main Execution ----------------------\n",
    "def main(source_path, reference_path):\n",
    "    # Load Mask R-CNN model\n",
    "    model = load_mask_rcnn()\n",
    "\n",
    "    # Load source and reference images\n",
    "    source_image = cv2.imread(source_path)\n",
    "    reference_image = cv2.imread(reference_path)\n",
    "\n",
    "    if source_image is None or reference_image is None:\n",
    "        raise FileNotFoundError(\"Source or Reference image not found!\")\n",
    "\n",
    "    # Convert images to Lab color space\n",
    "    source_lab = cv2.cvtColor(source_image, cv2.COLOR_BGR2LAB)\n",
    "    reference_lab = cv2.cvtColor(reference_image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Generate palettes\n",
    "    source_palette = generate_palette(source_lab)\n",
    "    reference_palette = generate_palette(reference_lab)\n",
    "\n",
    "    # Foreground-background segmentation using Mask R-CNN\n",
    "    source_mask = segment_foreground_background(source_image, model)\n",
    "\n",
    "    # Color transfer with consistency and chromatic aberration control\n",
    "    transferred_lab = transfer_colors(source_lab, reference_lab, source_palette, reference_palette, source_mask)\n",
    "    transferred_lab = maintain_consistency(transferred_lab, reference_lab, source_palette, reference_palette)\n",
    "\n",
    "    # Lighting optimization\n",
    "    final_result = optimize_lighting(transferred_lab, reference_lab)\n",
    "\n",
    "    # Convert back to BGR and save output\n",
    "    final_bgr = cv2.cvtColor(final_result.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "    cv2.imwrite(\"output.jpg\", final_bgr)\n",
    "\n",
    "    print(\"Color transfer completed successfully. Check 'output.jpg'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color transfer completed successfully. Check 'output.jpg'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    source_path = \"/home/neelraj-reddy/college/6th_sem/computer vision/project/A little survey on previous works/images/input.jpg\"  # Input source image\n",
    "    reference_path = \"/home/neelraj-reddy/college/6th_sem/computer vision/project/A little survey on previous works/images/reference.jpeg\"  # Input reference image\n",
    "    main(source_path, reference_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
