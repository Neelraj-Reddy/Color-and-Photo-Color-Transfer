{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelraj-reddy/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1920 but corresponding boolean dimension is 1994",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m target_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/neelraj-reddy/college/6th_sem/computer vision/project/A little survey on previous works/images/beach_ref.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Run hybrid color transfer with PCA-based alignment\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m result_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_color_transfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid_result_pca.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_bgr)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Run hybrid color transfer with Monge-Kantorovitch alignment\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mhybrid_color_transfer\u001b[0;34m(source_path, target_path, method)\u001b[0m\n\u001b[1;32m     42\u001b[0m match_dict \u001b[38;5;241m=\u001b[39m match_regions(src_feats, tgt_feats, wS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, wL\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, wR\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 5: Local Color Transfer\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m out_lab \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_color_transfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_bgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned_bgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m out_bgr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(out_lab, cv2\u001b[38;5;241m.\u001b[39mCOLOR_LAB2BGR)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_bgr\n",
      "File \u001b[0;32m~/college/6th_sem/computer vision/project/A little survey on previous works/work1.py:326\u001b[0m, in \u001b[0;36mlocal_color_transfer\u001b[0;34m(src_bgr, tgt_bgr, src_seg, tgt_seg, match_dict)\u001b[0m\n\u001b[1;32m    324\u001b[0m     src_stats[i] \u001b[38;5;241m=\u001b[39m compute_region_stats(src_lab, src_labels, i)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tgt_num_regions):\n\u001b[0;32m--> 326\u001b[0m     tgt_stats[j] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_region_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_lab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Local gamma parameters from eq. (12)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# We'll compute global L means:\u001b[39;00m\n\u001b[1;32m    330\u001b[0m src_global_L \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(src_lab[:,:,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/college/6th_sem/computer vision/project/A little survey on previous works/work1.py:309\u001b[0m, in \u001b[0;36mlocal_color_transfer.<locals>.compute_region_stats\u001b[0;34m(img_lab, labels, region_idx)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(mask):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# fallback\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m region_vals \u001b[38;5;241m=\u001b[39m \u001b[43mimg_lab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    310\u001b[0m L_ \u001b[38;5;241m=\u001b[39m region_vals[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    311\u001b[0m A_ \u001b[38;5;241m=\u001b[39m region_vals[:,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1920 but corresponding boolean dimension is 1994"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from work1 import estimate_dominant_colors, soft_segmentation, local_color_transfer, compute_region_features, match_regions\n",
    "from work2 import pca_transfer, monge_kantorovitch_transfer\n",
    "\n",
    "def hybrid_color_transfer(source_path, target_path, method=\"pca\"):\n",
    "    \"\"\"\n",
    "    Hybrid color transfer pipeline combining the best of work1.py and work2.py.\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    src_bgr = cv2.imread(source_path)\n",
    "    tgt_bgr = cv2.imread(target_path)\n",
    "    if src_bgr is None or tgt_bgr is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # Step 1: Dominant Color Estimation\n",
    "    src_dom = estimate_dominant_colors(src_bgr, grid_size=8, min_pixels=50)\n",
    "    tgt_dom = estimate_dominant_colors(tgt_bgr, grid_size=8, min_pixels=50)\n",
    "\n",
    "    # Step 2: Soft Segmentation\n",
    "    src_seg = soft_segmentation(src_bgr, src_dom)  # shape(H,W,Cs)\n",
    "    tgt_seg = soft_segmentation(tgt_bgr, tgt_dom)  # shape(H,W,Ct)\n",
    "\n",
    "    # Ensure the same number of dominant colors in both images\n",
    "    Cs = src_seg.shape[-1]\n",
    "    Ct = tgt_seg.shape[-1]\n",
    "    C_min = min(Cs, Ct)\n",
    "    src_seg = src_seg[:, :, :C_min]\n",
    "    tgt_seg = tgt_seg[:, :, :C_min]\n",
    "\n",
    "    # Step 3: Global Color Alignment\n",
    "    if method == \"pca\":\n",
    "        aligned_bgr = pca_transfer(src_bgr, tgt_bgr)\n",
    "    elif method == \"monge-kantorovitch\":\n",
    "        aligned_bgr = monge_kantorovitch_transfer(src_bgr, tgt_bgr)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'pca' or 'monge-kantorovitch'.\")\n",
    "\n",
    "    # Step 4: Region Matching\n",
    "    src_feats = compute_region_features(src_bgr, src_seg)\n",
    "    tgt_feats = compute_region_features(tgt_bgr, tgt_seg)\n",
    "    match_dict = match_regions(src_feats, tgt_feats, wS=1.0, wL=1.0, wR=1.0)\n",
    "\n",
    "    # Step 5: Local Color Transfer\n",
    "    out_lab = local_color_transfer(src_bgr, aligned_bgr, src_seg, tgt_seg, match_dict)\n",
    "    out_bgr = cv2.cvtColor(out_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return out_bgr\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    source_path = \"/home/neelraj-reddy/college/6th_sem/computer vision/project/A little survey on previous works/images/beach_target.jpeg\"\n",
    "    target_path = \"/home/neelraj-reddy/college/6th_sem/computer vision/project/A little survey on previous works/images/beach_ref.jpeg\"\n",
    "\n",
    "    # Run hybrid color transfer with PCA-based alignment\n",
    "    result_bgr = hybrid_color_transfer(source_path, target_path, method=\"pca\")\n",
    "    cv2.imwrite(\"hybrid_result_pca.jpg\", result_bgr)\n",
    "\n",
    "    # Run hybrid color transfer with Monge-Kantorovitch alignment\n",
    "    result_bgr = hybrid_color_transfer(source_path, target_path, method=\"monge-kantorovitch\")\n",
    "    cv2.imwrite(\"hybrid_result_mk.jpg\", result_bgr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
