{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.segmentation import slic\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import color as skcolor\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "##############################################################################\n",
    "# Utility Functions\n",
    "##############################################################################\n",
    "\n",
    "def rgb_to_hsv_np(img):\n",
    "    \"\"\"Convert an RGB image [0..1] to HSV [0..1], using skimage for convenience.\"\"\"\n",
    "    # skimage.color.rgb2hsv expects float64 in [0..1].\n",
    "    return skcolor.rgb2hsv(img.astype(np.float64))\n",
    "\n",
    "def hsv_to_rgb_np(img):\n",
    "    \"\"\"Convert an HSV image [0..1] to RGB [0..1], using skimage for convenience.\"\"\"\n",
    "    return skcolor.hsv2rgb(img)\n",
    "\n",
    "def bgr_to_lab(img_bgr):\n",
    "    \"\"\"Convert a BGR [0..255] image to Lab [0..255] using OpenCV.\"\"\"\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "def lab_to_bgr(img_lab):\n",
    "    \"\"\"Convert a Lab [0..255] image to BGR [0..255] using OpenCV.\"\"\"\n",
    "    return cv2.cvtColor(img_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def delta_e94(lab1, lab2):\n",
    "    \"\"\"\n",
    "    Approximate ΔE94 between two Lab colors.\n",
    "    Each is (L, a, b). This is a simplified version from the paper.\n",
    "    \"\"\"\n",
    "    # Paper uses: ΔE94 = sqrt((ΔL/KL)^2 + (ΔAB/(1 + K1*AB1))^2 + (ΔH/(1 + K2*AB1))^2)\n",
    "    # We'll do a simpler approach or partial approach for demonstration.\n",
    "\n",
    "    L1, a1, b1 = lab1\n",
    "    L2, a2, b2 = lab2\n",
    "    dL = L1 - L2\n",
    "    C1 = math.sqrt(a1*a1 + b1*b1)\n",
    "    C2 = math.sqrt(a2*a2 + b2*b2)\n",
    "    dC = C1 - C2\n",
    "    dA = a1 - a2\n",
    "    dB = b1 - b2\n",
    "    dH_sq = (dA*dA + dB*dB - dC*dC) if (dC*dC <= (dA*dA + dB*dB)) else 0.0\n",
    "\n",
    "    # Constants from paper:\n",
    "    KL = 2.0\n",
    "    K1 = 0.048\n",
    "    K2 = 0.014\n",
    "\n",
    "    # We compute approximate AB1 as the average of C1, from the paper's eqn:\n",
    "    AB1 = C1\n",
    "    # For simplicity, we do a direct approach:\n",
    "    termL = (dL / KL)**2\n",
    "    termC = (dC / (1 + K1 * AB1))**2\n",
    "    termH = (math.sqrt(abs(dH_sq)) / (1 + K2 * AB1))**2\n",
    "\n",
    "    return math.sqrt(termL + termC + termH)\n",
    "\n",
    "def compute_saliency_opencv(img_bgr):\n",
    "    \"\"\"Compute saliency using OpenCV's spectral residual method.\"\"\"\n",
    "    saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
    "    success, saliency_map = saliency.computeSaliency(img_bgr)\n",
    "    if not success:\n",
    "        # fallback: just return grayscale\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        return gray.astype(np.float32) / 255.0\n",
    "    return saliency_map.astype(np.float32)\n",
    "\n",
    "def guided_filter_color(I, p, radius=5, eps=1e-3):\n",
    "    \"\"\"\n",
    "    Simple approximate guided filter using OpenCV's ximgproc if available.\n",
    "    If not, we do a basic bilateral filter fallback.\n",
    "    \"\"\"\n",
    "    # Try to import guided filter from opencv-contrib\n",
    "    try:\n",
    "        import cv2.ximgproc as xip\n",
    "        # p and I must be 8-bit or 32F\n",
    "        if p.dtype != np.float32:\n",
    "            p = p.astype(np.float32)\n",
    "        if I.dtype != np.float32:\n",
    "            I = I.astype(np.float32)\n",
    "        guided = xip.guidedFilter(I, p, radius, eps)\n",
    "        return guided\n",
    "    except ImportError:\n",
    "        # fallback: use a bilateral filter as a rough approximation\n",
    "        return cv2.bilateralFilter(p, radius*2+1, 75, 75)\n",
    "\n",
    "##############################################################################\n",
    "# 1. Dominant Color Estimation (Grid-based in HSV)\n",
    "##############################################################################\n",
    "\n",
    "def estimate_dominant_colors(img_bgr, grid_size=8, min_pixels=50):\n",
    "    \"\"\"\n",
    "    Implements the grid-based dominant color estimation in HSV from the paper (Sec. 3.1.1),\n",
    "    but in a simplified manner:\n",
    "      1. Convert image to HSV.\n",
    "      2. Create a 3D histogram with shape [grid_size, grid_size, grid_size].\n",
    "      3. Remove outlier bins using a threshold (3-sigma or min_pixels).\n",
    "      4. Merge connected bins to find final 'dominant color' centroids.\n",
    "    Returns a list of HSV colors in [0..255].\n",
    "    \"\"\"\n",
    "    h, w, _ = img_bgr.shape\n",
    "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)  # each channel [0..180] for H, [0..255] for S,V\n",
    "\n",
    "    # 3D histogram: We'll use integer binning. H range: 0..180, S range: 0..256, V range: 0..256\n",
    "    # We want grid_size bins for each channel => bin width:\n",
    "    h_bin = 180 / grid_size\n",
    "    s_bin = 256 / grid_size\n",
    "    v_bin = 256 / grid_size\n",
    "\n",
    "    # Build the histogram\n",
    "    hist_3d = np.zeros((grid_size, grid_size, grid_size), dtype=np.int32)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            H, S, V = img_hsv[y, x]\n",
    "            hi = int(H // h_bin)\n",
    "            si = int(S // s_bin)\n",
    "            vi = int(V // v_bin)\n",
    "            if hi >= grid_size: hi = grid_size - 1\n",
    "            if si >= grid_size: si = grid_size - 1\n",
    "            if vi >= grid_size: vi = grid_size - 1\n",
    "            hist_3d[hi, si, vi] += 1\n",
    "\n",
    "    # Remove outliers (bins with fewer than min_pixels)\n",
    "    mask = (hist_3d >= min_pixels).astype(np.uint8)\n",
    "\n",
    "    # We now find connected components in 3D (26-neighborhood).\n",
    "    # We'll label them and compute centroids in HSV bin space.\n",
    "    labeled = label(mask, connectivity=3)  # scikit-image 3D labeling\n",
    "    regions = regionprops(labeled)\n",
    "    dominant_hsv = []\n",
    "    for r in regions:\n",
    "        # regionprops centroid is in (z,y,x) order if 3D, but our labeling might be (hi,si,vi).\n",
    "        coords = r.coords  # list of (hi, si, vi)\n",
    "        total_count = 0\n",
    "        sumH = 0\n",
    "        sumS = 0\n",
    "        sumV = 0\n",
    "        for (hi, si, vi) in coords:\n",
    "            count = hist_3d[hi, si, vi]\n",
    "            # The actual H, S, V center of that bin\n",
    "            # center in bin space => hi+0.5, etc.\n",
    "            # Convert bin index -> actual H,S,V\n",
    "            # H in [0..180], bin width = h_bin => actual H ~ (hi+0.5)*h_bin\n",
    "            # We'll weight by the # of pixels in that bin\n",
    "            sumH += ( (hi + 0.5)*h_bin ) * count\n",
    "            sumS += ( (si + 0.5)*s_bin ) * count\n",
    "            sumV += ( (vi + 0.5)*v_bin ) * count\n",
    "            total_count += count\n",
    "\n",
    "        if total_count > 0:\n",
    "            cH = sumH / total_count\n",
    "            cS = sumS / total_count\n",
    "            cV = sumV / total_count\n",
    "            # store as integer\n",
    "            cH = np.clip(cH, 0, 179)\n",
    "            cS = np.clip(cS, 0, 255)\n",
    "            cV = np.clip(cV, 0, 255)\n",
    "            dominant_hsv.append([cH, cS, cV])\n",
    "\n",
    "    # Return as a list of HSV in [0..255], H in [0..179].\n",
    "    # The paper merges them further if needed. We'll just return them.\n",
    "    return dominant_hsv\n",
    "\n",
    "##############################################################################\n",
    "# 2. Soft Segmentation via Cost Volume + Guided Filtering\n",
    "##############################################################################\n",
    "\n",
    "def soft_segmentation(img_bgr, dom_hsv_list):\n",
    "    \"\"\"\n",
    "    Soft-segment the image based on the dominant colors (Sec. 3.1.2).\n",
    "    Steps:\n",
    "      1) Convert each dominant color to Lab for cost computation.\n",
    "      2) For each pixel, compute cost = ΔE94(Lab_pixel, Lab_dominant).\n",
    "      3) Filter cost volumes with a guided filter (paper used cost-volume filtering).\n",
    "      4) Convert to soft segmentation by normalized exp(-cost).\n",
    "    Returns: seg_map with shape [H,W,len(dom_hsv_list)] => sum over last dim = 1.\n",
    "    \"\"\"\n",
    "    H, W, _ = img_bgr.shape\n",
    "    img_lab = bgr_to_lab(img_bgr).astype(np.float32)\n",
    "    # Precompute Lab for each pixel\n",
    "    lab_pixels = img_lab.reshape(-1, 3)\n",
    "\n",
    "    # Convert each dominant HSV to BGR->Lab for cost\n",
    "    dom_lab_list = []\n",
    "    for hsv in dom_hsv_list:\n",
    "        color_bgr = np.uint8([[hsv]])  # shape(1,1,3) in HSV\n",
    "        color_bgr = cv2.cvtColor(color_bgr, cv2.COLOR_HSV2BGR)\n",
    "        color_lab = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2LAB)[0,0,:].astype(np.float32)\n",
    "        dom_lab_list.append(color_lab)\n",
    "\n",
    "    # Build cost volumes\n",
    "    cost_volumes = []\n",
    "    for cidx, dom_lab in enumerate(dom_lab_list):\n",
    "        cost_map = np.zeros((H, W), dtype=np.float32)\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                Lp, Ap, Bp = img_lab[i,j]\n",
    "                cost_map[i,j] = delta_e94((Lp,Ap,Bp), dom_lab)\n",
    "        # Filter cost_map with guided filter using the original image as guidance\n",
    "        # (paper uses cost-volume filtering, we approximate with guidedFilter on each slice).\n",
    "        # Convert BGR to float32 for guided filter\n",
    "        guided = img_bgr.astype(np.float32) / 255.0\n",
    "        cost_map_filtered = guided_filter_color(guided, cost_map, radius=5, eps=1e-3)\n",
    "        cost_volumes.append(cost_map_filtered)\n",
    "\n",
    "    # Convert cost to soft membership\n",
    "    # We'll do: membership = exp(-cost / alpha), then normalize\n",
    "    alpha = 10.0  # scale factor to control softness\n",
    "    seg_stack = []\n",
    "    for cvm in cost_volumes:\n",
    "        seg_stack.append(np.exp(-cvm / alpha))\n",
    "\n",
    "    seg_stack = np.stack(seg_stack, axis=-1)  # shape(H,W,#dom)\n",
    "    sum_ = np.sum(seg_stack, axis=-1, keepdims=True)\n",
    "    sum_ = np.clip(sum_, 1e-8, None)\n",
    "    seg_stack /= sum_\n",
    "    return seg_stack\n",
    "\n",
    "##############################################################################\n",
    "# 3. Region Matching\n",
    "##############################################################################\n",
    "\n",
    "def compute_region_features(img_bgr, seg_stack):\n",
    "    \"\"\"\n",
    "    Compute region features: saliency, luminance, pixel ratio for each\n",
    "    dominant-color region. We'll pick the argmax per pixel as 'hard region label'\n",
    "    to measure stats. (Paper does 'winner-take-all' in cost volume).\n",
    "    \"\"\"\n",
    "    H, W, C = seg_stack.shape\n",
    "    # Hard assignment\n",
    "    labels = np.argmax(seg_stack, axis=-1).astype(np.int32)  # shape(H,W)\n",
    "    # Saliency map\n",
    "    sal_map = compute_saliency_opencv(img_bgr)\n",
    "\n",
    "    # Luminance from Lab\n",
    "    img_lab = bgr_to_lab(img_bgr)\n",
    "    L_chan = img_lab[:,:,0].astype(np.float32)\n",
    "\n",
    "    # For each region, compute average saliency, average L, and pixel ratio\n",
    "    region_feats = []\n",
    "    total_pixels = H*W\n",
    "    for ridx in range(C):\n",
    "        mask = (labels == ridx)\n",
    "        pix_count = np.sum(mask)\n",
    "        if pix_count < 1:\n",
    "            region_feats.append((0,0,0))  # fallback\n",
    "            continue\n",
    "        mean_sal = np.mean(sal_map[mask])\n",
    "        mean_lum = np.mean(L_chan[mask])\n",
    "        ratio = float(pix_count) / total_pixels\n",
    "        region_feats.append((mean_sal, mean_lum, ratio))\n",
    "    return region_feats\n",
    "\n",
    "def match_regions(src_feats, tgt_feats, wS=1.0, wL=1.0, wR=1.0):\n",
    "    \"\"\"\n",
    "    From paper eq. (6):\n",
    "    We find for each src region i => best match j in target that minimizes:\n",
    "       sqrt( wS*(S_i - S_j)^2 + wL*(L_i - L_j)^2 + wR*(R_i - R_j)^2 )\n",
    "    Returns a dict: match[i] = j\n",
    "    \"\"\"\n",
    "    match_dict = {}\n",
    "    for i, (sS, sL, sR) in enumerate(src_feats):\n",
    "        best_j = None\n",
    "        best_dist = 1e10\n",
    "        for j, (tS, tL, tR) in enumerate(tgt_feats):\n",
    "            dS = (sS - tS)\n",
    "            dL = (sL - tL)\n",
    "            dR = (sR - tR)\n",
    "            dist = math.sqrt(wS*(dS**2) + wL*(dL**2) + wR*(dR**2))\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_j = j\n",
    "        match_dict[i] = best_j\n",
    "    return match_dict\n",
    "\n",
    "##############################################################################\n",
    "# 4. Local Color Transfer with Modified Reinhard + Local Gamma\n",
    "##############################################################################\n",
    "\n",
    "def local_color_transfer(src_bgr, tgt_bgr, src_seg, tgt_seg, match_dict):\n",
    "    \"\"\"\n",
    "    Implements eq. (10)-(12) from paper in a simplified manner:\n",
    "      - We separate each region in src & tgt\n",
    "      - For a,b channels => standard Reinhard per region\n",
    "      - For L => local gamma correction\n",
    "    We then blend the results using the soft segmentation from src_seg.\n",
    "    \"\"\"\n",
    "    H, W, C = src_seg.shape\n",
    "    src_lab = bgr_to_lab(src_bgr).astype(np.float32)\n",
    "    tgt_lab = bgr_to_lab(tgt_bgr).astype(np.float32)\n",
    "\n",
    "    # Hard labels\n",
    "    src_labels = np.argmax(src_seg, axis=-1)  # shape(H,W)\n",
    "    tgt_labels = np.argmax(tgt_seg, axis=-1)\n",
    "\n",
    "    # We'll build an output Lab\n",
    "    out_lab = np.zeros_like(src_lab)\n",
    "\n",
    "    # Precompute region stats (mean, std) for L, a, b in both images\n",
    "    def compute_region_stats(img_lab, labels, region_idx):\n",
    "        \"\"\"Compute (meanL, stdL, meanA, stdA, meanB, stdB) for the given region.\"\"\"\n",
    "        mask = (labels == region_idx)\n",
    "        if not np.any(mask):\n",
    "            return (0,1, 0,1, 0,1)  # fallback\n",
    "        region_vals = img_lab[mask]\n",
    "        L_ = region_vals[:,0]\n",
    "        A_ = region_vals[:,1]\n",
    "        B_ = region_vals[:,2]\n",
    "        return (np.mean(L_), np.std(L_)+1e-6,\n",
    "                np.mean(A_), np.std(A_)+1e-6,\n",
    "                np.mean(B_), np.std(B_)+1e-6)\n",
    "\n",
    "    # We'll store region stats in dict for source & target\n",
    "    src_stats = {}\n",
    "    tgt_stats = {}\n",
    "    src_num_regions = C\n",
    "    tgt_num_regions = C\n",
    "\n",
    "    for i in range(src_num_regions):\n",
    "        src_stats[i] = compute_region_stats(src_lab, src_labels, i)\n",
    "    for j in range(tgt_num_regions):\n",
    "        tgt_stats[j] = compute_region_stats(tgt_lab, tgt_labels, j)\n",
    "\n",
    "    # Local gamma parameters from eq. (12)\n",
    "    # We'll compute global L means:\n",
    "    src_global_L = np.mean(src_lab[:,:,0])\n",
    "    tgt_global_L = np.mean(tgt_lab[:,:,0])\n",
    "\n",
    "    # For each pixel in src, do:\n",
    "    #   region i => matched region j\n",
    "    #   a*, b* => eq. (10),(11)\n",
    "    #   L => eq. (12) local gamma\n",
    "    out_L = np.zeros((H,W), dtype=np.float32)\n",
    "    out_A = np.zeros((H,W), dtype=np.float32)\n",
    "    out_B = np.zeros((H,W), dtype=np.float32)\n",
    "\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            ridx = src_labels[i,j]\n",
    "            matched_r = match_dict[ridx]\n",
    "            # get stats\n",
    "            sMeanL, sStdL, sMeanA, sStdA, sMeanB, sStdB = src_stats[ridx]\n",
    "            tMeanL, tStdL, tMeanA, tStdA, tMeanB, tStdB = tgt_stats[matched_r]\n",
    "\n",
    "            Lp, Ap, Bp = src_lab[i,j]\n",
    "\n",
    "            # eq. (10),(11) for a,b\n",
    "            a_new = ((Ap - sMeanA) * (tStdA / sStdA)) + tMeanA\n",
    "            b_new = ((Bp - sMeanB) * (tStdB / sStdB)) + tMeanB\n",
    "\n",
    "            # eq. (12) for L => local gamma\n",
    "            # gamma_i = |beta_i + alpha*(μLs - μLt)|\n",
    "            #   beta_i = [1 + 2(μli - μlj)]\n",
    "            #   alpha = exp( |Ls - Lt| * (μli/μLs - μlj/μLt) )\n",
    "            # We'll interpret \"μli\" as sMeanL, \"μlj\" as tMeanL\n",
    "            # and Ls=src_global_L, Lt=tgt_global_L\n",
    "            mu_li = sMeanL\n",
    "            mu_lj = tMeanL\n",
    "            Ls = src_global_L\n",
    "            Lt = tgt_global_L\n",
    "\n",
    "            beta_i = (1.0 + 2.0*(mu_li - mu_lj)/255.0)  # scaled by 255\n",
    "            # Protect from negative or zero\n",
    "            # alpha_i = exp(|Ls - Lt| * ( (mu_li/μLs) - (mu_lj/μLt) ))\n",
    "            # The paper's exact formula is a bit ambiguous; we do a best guess:\n",
    "            #   alpha = exp( |Ls-Lt| * ( (mu_li/Ls) - (mu_lj/Lt) ) )\n",
    "            # We'll clamp to avoid negative or zero denominators\n",
    "            Ls = max(Ls, 1e-6)\n",
    "            Lt = max(Lt, 1e-6)\n",
    "            alpha_i = math.exp(abs(Ls - Lt) * ((mu_li/Ls) - (mu_lj/Lt)))\n",
    "\n",
    "            gamma_i = abs(beta_i + alpha_i*(Ls - Lt)/255.0)  # extra scaling\n",
    "            # now L' = L^gamma_i, but we want to keep it in [0..255].\n",
    "            # The paper's eq. (12) says: L0 = sum( (Li)^gamma_i ), but we have per-pixel approach\n",
    "            # We'll do: L_new = (Lp/255)^gamma_i * 255\n",
    "            # This is a simplified approach.\n",
    "            Lp_norm = Lp / 255.0\n",
    "            L_new = (Lp_norm ** gamma_i) * 255.0\n",
    "\n",
    "            out_L[i,j] = np.clip(L_new, 0, 255)\n",
    "            out_A[i,j] = np.clip(a_new, 0, 255)\n",
    "            out_B[i,j] = np.clip(b_new, 0, 255)\n",
    "\n",
    "    # Combine into Lab\n",
    "    combined_lab = np.stack([out_L, out_A, out_B], axis=-1).astype(np.uint8)\n",
    "\n",
    "    # Because we did a \"hard\" approach per pixel, we can blend with the soft weights from src_seg\n",
    "    # But the paper merges them region by region. We'll do a simpler approach:\n",
    "    #   out_lab is final.\n",
    "    return combined_lab\n",
    "\n",
    "##############################################################################\n",
    "# Main Pipeline\n",
    "##############################################################################\n",
    "\n",
    "def local_color_transfer_pipeline(source_path, target_path):\n",
    "    \"\"\"\n",
    "    Full pipeline from the Yoo et al. paper, approximate version.\n",
    "    1) Estimate dominant colors in both images.\n",
    "    2) Soft-segment both images.\n",
    "    3) Region matching by saliency, luminance, pixel ratio.\n",
    "    4) Local color transfer with local gamma correction.\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    src_bgr = cv2.imread(source_path)\n",
    "    tgt_bgr = cv2.imread(target_path)\n",
    "    if src_bgr is None or tgt_bgr is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # 1) Dominant colors\n",
    "    src_dom = estimate_dominant_colors(src_bgr, grid_size=8, min_pixels=50)\n",
    "    tgt_dom = estimate_dominant_colors(tgt_bgr, grid_size=8, min_pixels=50)\n",
    "\n",
    "    # 2) Soft segmentation\n",
    "    src_seg = soft_segmentation(src_bgr, src_dom)  # shape(H,W,Cs)\n",
    "    tgt_seg = soft_segmentation(tgt_bgr, tgt_dom)  # shape(H,W,Ct)\n",
    "\n",
    "    # For simplicity, we assume the same number of dominant colors in both images.\n",
    "    # If they differ, you can keep only the min(C_s, C_t) largest segments or similar.\n",
    "    # We'll just truncate to min length:\n",
    "    Cs = src_seg.shape[-1]\n",
    "    Ct = tgt_seg.shape[-1]\n",
    "    C_min = min(Cs, Ct)\n",
    "    src_seg = src_seg[:,:,:C_min]\n",
    "    tgt_seg = tgt_seg[:,:,:C_min]\n",
    "\n",
    "    # 3) Region matching\n",
    "    src_feats = compute_region_features(src_bgr, src_seg)\n",
    "    tgt_feats = compute_region_features(tgt_bgr, tgt_seg)\n",
    "    match_dict = match_regions(src_feats, tgt_feats, wS=1.0, wL=1.0, wR=1.0)\n",
    "\n",
    "    # 4) Local color transfer\n",
    "    out_lab = local_color_transfer(src_bgr, tgt_bgr, src_seg, tgt_seg, match_dict)\n",
    "    out_bgr = lab_to_bgr(out_lab)\n",
    "    return out_bgr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Demo Main\n",
    "##############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage with the two beach images:\n",
    "    source_path = \"reference.jpeg\"  # The image to be recolored\n",
    "    target_path = \"input.jpg\"     # The reference style image\n",
    "\n",
    "    result_bgr = local_color_transfer_pipeline(source_path, target_path)\n",
    "    out_name = \"local_color_result.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load original and target images\n",
    "source_img = cv2.imread(source_path)\n",
    "target_img = cv2.imread(target_path)\n",
    "\n",
    "# Convert BGR to RGB for correct color display in matplotlib\n",
    "source_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)\n",
    "target_rgb = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)\n",
    "result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot all three images for comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(source_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"Source Image\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(target_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"Target Image\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(result_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"Color Transferred Image\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.segmentation import slic\n",
    "from skimage.measure import regionprops\n",
    "from skimage import color as skcolor\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Load pre-trained ResNet for feature extraction\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.feature_layer = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_layer(x)\n",
    "        return x.view(x.shape[0], -1)  # Flatten feature maps\n",
    "\n",
    "# Preprocess images for ResNet\n",
    "def preprocess_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "# Compute deep features for regions\n",
    "def compute_deep_features(img_bgr, seg_map, model, device):\n",
    "    H, W, num_regions = seg_map.shape\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    region_features = []\n",
    "\n",
    "    for ridx in range(num_regions):\n",
    "        mask = seg_map[:, :, ridx] > 0.5  # Threshold for hard segmentation\n",
    "        if np.sum(mask) == 0:\n",
    "            region_features.append(np.zeros(2048))  # ResNet50 feature size\n",
    "            continue\n",
    "\n",
    "        # Extract region and resize for ResNet\n",
    "        region = img_rgb * np.expand_dims(mask, axis=-1)\n",
    "        region = np.uint8(region)\n",
    "        region_resized = cv2.resize(region, (224, 224))\n",
    "\n",
    "        # Compute deep features\n",
    "        region_tensor = preprocess_image(region_resized).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = model(region_tensor)\n",
    "        region_features.append(features.cpu().numpy().flatten())\n",
    "\n",
    "    return np.array(region_features)\n",
    "\n",
    "# Match regions using deep features and cosine similarity\n",
    "def match_regions_deep(src_feats, tgt_feats):\n",
    "    distances = cdist(src_feats, tgt_feats, metric='cosine')  # Cosine similarity\n",
    "    matches = np.argmin(distances, axis=1)  # Find best match for each source region\n",
    "    return {i: matches[i] for i in range(len(src_feats))}\n",
    "\n",
    "# Local Color Transfer Pipeline\n",
    "def local_color_transfer_pipeline(source_path, target_path):\n",
    "    # Load images\n",
    "    src_bgr = cv2.imread(source_path)\n",
    "    tgt_bgr = cv2.imread(target_path)\n",
    "    if src_bgr is None or tgt_bgr is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # Step 1: Estimate Dominant Colors (Same as Before)\n",
    "    src_dominant_hsv = estimate_dominant_colors(src_bgr)\n",
    "    tgt_dominant_hsv = estimate_dominant_colors(tgt_bgr)\n",
    "\n",
    "    # Step 2: Soft Segmentation\n",
    "    src_seg = soft_segmentation(src_bgr, src_dominant_hsv)\n",
    "    tgt_seg = soft_segmentation(tgt_bgr, tgt_dominant_hsv)\n",
    "\n",
    "    # Step 3: Deep Learning-Based Region Matching\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FeatureExtractor().to(device).eval()\n",
    "\n",
    "    src_feats = compute_deep_features(src_bgr, src_seg, model, device)\n",
    "    tgt_feats = compute_deep_features(tgt_bgr, tgt_seg, model, device)\n",
    "    match_dict = match_regions_deep(src_feats, tgt_feats)\n",
    "\n",
    "    # Step 4: Local Color Transfer\n",
    "    output_lab = local_color_transfer(src_bgr, tgt_bgr, src_seg, tgt_seg, match_dict)\n",
    "\n",
    "    # Convert to BGR and save\n",
    "    output_bgr = lab_to_bgr(output_lab)\n",
    "    cv2.imwrite(\"output.png\", output_bgr)\n",
    "    print(\"Color transfer completed. Output saved as output.png\")\n",
    "\n",
    "# Run the pipeline\n",
    "source_img = \"input.jpg\"\n",
    "target_img = \"reference.jpeg\"\n",
    "local_color_transfer_pipeline(source_img, target_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_segmentation(image, k=4):\n",
    "    # Convert image to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Reshape the image to a 2D array of pixels (each row represents a pixel)\n",
    "    pixels = hsv_image.reshape((-1, 3))\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(pixels)\n",
    "    \n",
    "    # Reshape the labels back to the original image shape\n",
    "    segmented_image = kmeans.labels_.reshape(image.shape[0], image.shape[1])\n",
    "    \n",
    "    return segmented_image, kmeans.cluster_centers_\n",
    "\n",
    "def apply_color_transfer(source_image, target_image, segmented_image, cluster_centers):\n",
    "    # Convert both images to HSV color space\n",
    "    source_hsv = cv2.cvtColor(source_image, cv2.COLOR_BGR2HSV)\n",
    "    target_hsv = cv2.cvtColor(target_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply color transfer based on cluster centers\n",
    "    for i in range(len(cluster_centers)):\n",
    "        # Find the pixels in the target image that belong to this cluster\n",
    "        target_cluster_pixels = (segmented_image == i)\n",
    "        \n",
    "        # For each pixel, adjust the color to match the source's corresponding cluster\n",
    "        source_cluster_center = cluster_centers[i]\n",
    "        target_hsv[target_cluster_pixels] = source_cluster_center\n",
    "        \n",
    "    # Convert the result back to BGR color space\n",
    "    result_image = cv2.cvtColor(target_hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Load source and target images\n",
    "source_image = cv2.imread('input.jpg')\n",
    "target_image = cv2.imread('reference.jpeg')\n",
    "\n",
    "# Apply K-means segmentation to the target image\n",
    "segmented_image, cluster_centers = kmeans_segmentation(target_image, k=2)\n",
    "\n",
    "# Apply color transfer using K-means segmented regions\n",
    "result_image = apply_color_transfer(source_image, target_image, segmented_image, cluster_centers)\n",
    "\n",
    "# Save and show the result\n",
    "cv2.imwrite('result_image.jpg', result_image)\n",
    "cv2.imshow('Result Image', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def dbscan_segmentation(image, eps=20, min_samples=100):\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Reshape the image into a 2D array of pixels\n",
    "    pixels = hsv_image.reshape((-1, 3))\n",
    "    \n",
    "    # Apply DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    dbscan_labels = dbscan.fit_predict(pixels)\n",
    "    \n",
    "    # Reshape the labels back to the original image dimensions\n",
    "    segmented_image = dbscan_labels.reshape(image.shape[0], image.shape[1])\n",
    "    \n",
    "    return segmented_image, dbscan_labels\n",
    "\n",
    "def apply_color_transfer(source_image, target_image, segmented_image, cluster_centers):\n",
    "    # Convert both images to HSV color space\n",
    "    source_hsv = cv2.cvtColor(source_image, cv2.COLOR_BGR2HSV)\n",
    "    target_hsv = cv2.cvtColor(target_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Assign each cluster in the target image the corresponding cluster color from the source\n",
    "    for i in range(len(cluster_centers)):\n",
    "        target_cluster_pixels = (segmented_image == i)\n",
    "        source_cluster_center = cluster_centers[i]\n",
    "        target_hsv[target_cluster_pixels] = source_cluster_center\n",
    "    \n",
    "    # Convert the result back to BGR color space\n",
    "    result_image = cv2.cvtColor(target_hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Load source and target images\n",
    "source_image = cv2.imread('input.jpg')\n",
    "target_image = cv2.imread('reference.jpeg')\n",
    "\n",
    "# Apply DBSCAN segmentation to the target image\n",
    "segmented_image, dbscan_labels = dbscan_segmentation(target_image, eps=20, min_samples=100)\n",
    "\n",
    "# Find cluster centers (mean color of each cluster)\n",
    "unique_labels = np.unique(dbscan_labels)\n",
    "cluster_centers = []\n",
    "\n",
    "for label in unique_labels:\n",
    "    if label != -1:  # Ignore noise (-1)\n",
    "        cluster_pixels = target_image[dbscan_labels == label]\n",
    "        cluster_center = np.mean(cluster_pixels, axis=0)\n",
    "        cluster_centers.append(cluster_center)\n",
    "\n",
    "# Apply color transfer using DBSCAN segmented regions\n",
    "result_image = apply_color_transfer(source_image, target_image, segmented_image, cluster_centers)\n",
    "\n",
    "# Show the result using Matplotlib (no OpenCV windows)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the original target image and the result\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Target Image')\n",
    "plt.imshow(cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Result Image with Color Transfer')\n",
    "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############################################\n",
    "# Mean-Shift Segmentation\n",
    "#############################################\n",
    "\n",
    "def mean_shift_segmentation(img_bgr, sp=21, sr=51):\n",
    "    filtered = cv2.pyrMeanShiftFiltering(img_bgr, sp, sr)\n",
    "    return filtered\n",
    "\n",
    "#############################################\n",
    "# Edge Detection and Processing\n",
    "#############################################\n",
    "\n",
    "def compute_edge_mask(img_bgr, low_threshold=50, high_threshold=150, dilation_iters=1):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges_dilated = cv2.dilate(edges, kernel, iterations=dilation_iters)\n",
    "    return edges_dilated > 0\n",
    "\n",
    "#############################################\n",
    "# Region Labeling from Mean-Shift Output\n",
    "#############################################\n",
    "\n",
    "def label_regions(filtered_img):\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    labeled = label(thresh)\n",
    "    return labeled\n",
    "\n",
    "#############################################\n",
    "# Apply Tint to a Region (Basic Blend)\n",
    "#############################################\n",
    "\n",
    "def apply_tint_to_region(img_bgr, region_mask, tint_color, blend=0.5):\n",
    "    tinted = img_bgr.copy()\n",
    "    tint_img = np.full_like(img_bgr, tint_color)\n",
    "    tinted[region_mask] = cv2.addWeighted(img_bgr[region_mask], 1 - blend,\n",
    "                                          tint_img[region_mask], blend, 0)\n",
    "    return tinted\n",
    "\n",
    "#############################################\n",
    "# Color Transfer Methods\n",
    "#############################################\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    if method == \"svd\":\n",
    "        U, S, Vt = np.linalg.svd(matrix)\n",
    "        return np.dot(U, np.dot(np.diag(np.sqrt(S)), Vt))\n",
    "    elif method == \"eigen\":\n",
    "        eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "        sqrt_diag = np.diag(np.sqrt(eigvals))\n",
    "        return eigvecs @ sqrt_diag @ eigvecs.T\n",
    "    elif method == \"cholesky\":\n",
    "        return np.linalg.cholesky(matrix)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method for matrix square root\")\n",
    "\n",
    "def separable_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    scale = np.sqrt(np.diag(cov_r)) / np.sqrt(np.diag(cov_t))\n",
    "    transform = np.diag(scale)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def cholesky_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    L_t = np.linalg.cholesky(cov_t)\n",
    "    L_r = np.linalg.cholesky(cov_r)\n",
    "    transform = L_r @ np.linalg.inv(L_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def pca_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def monge_kantorovitch_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"svd\")\n",
    "    inv_sqrt_cov_t = np.linalg.inv(sqrt_cov_t)\n",
    "    mk_transform = inv_sqrt_cov_t @ sqrtm(sqrt_cov_t @ cov_r @ sqrt_cov_t, method=\"svd\") @ inv_sqrt_cov_t\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), mk_transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "# A helper to choose the transfer method\n",
    "def color_transfer(target, reference, method=\"pca\"):\n",
    "    if method == \"separable\":\n",
    "        return separable_transfer(target, reference)\n",
    "    elif method == \"cholesky\":\n",
    "        return cholesky_transfer(target, reference)\n",
    "    elif method == \"pca\":\n",
    "        return pca_transfer(target, reference)\n",
    "    elif method == \"monge_kantorovitch\":\n",
    "        return monge_kantorovitch_transfer(target, reference)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown color transfer method.\")\n",
    "\n",
    "#############################################\n",
    "# Integrated Processing Pipeline\n",
    "#############################################\n",
    "\n",
    "def process_image(src_path, tgt_path, transfer_method=None, region_based_transfer=False):\n",
    "    \"\"\"\n",
    "    Process the target image by:\n",
    "    1. Applying mean-shift segmentation.\n",
    "    2. Detecting edges.\n",
    "    3. Labeling regions.\n",
    "    4. For each region, either apply:\n",
    "         a. A basic tint (using the mean color from the source) with edge-aware blending, or\n",
    "         b. A color transfer (global or per-region) using the selected transfer method.\n",
    "    \n",
    "    Parameters:\n",
    "      transfer_method: One of \"separable\", \"cholesky\", \"pca\", \"monge_kantorovitch\".\n",
    "                       If None, the basic tint (mean blending) is used.\n",
    "      region_based_transfer: If True, apply the transfer method on each segmented region.\n",
    "                             If False, apply a global transfer to the whole image.\n",
    "    \"\"\"\n",
    "    src = cv2.imread(src_path)\n",
    "    tgt = cv2.imread(tgt_path)\n",
    "    if src is None or tgt is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # Resize source to target size if necessary\n",
    "    if src.shape != tgt.shape:\n",
    "        src = cv2.resize(src, (tgt.shape[1], tgt.shape[0]))\n",
    "\n",
    "    # Apply mean-shift segmentation and edge detection\n",
    "    ms_tgt = mean_shift_segmentation(tgt, sp=21, sr=51)\n",
    "    edge_mask = compute_edge_mask(tgt, low_threshold=50, high_threshold=150, dilation_iters=1)\n",
    "    labels = label_regions(ms_tgt)\n",
    "    props = regionprops(labels)\n",
    "    \n",
    "    out_img = tgt.copy()\n",
    "\n",
    "    # Option 1: Global color transfer\n",
    "    if transfer_method is not None and not region_based_transfer:\n",
    "        # Apply the selected color transfer to the full images.\n",
    "        out_img = color_transfer(tgt, src, method=transfer_method)\n",
    "        return out_img\n",
    "\n",
    "    # Option 2: Per-region processing (basic tint or color transfer)\n",
    "    for prop in props:\n",
    "        region_mask = (labels == prop.label)\n",
    "        if np.sum(region_mask) < 50:\n",
    "            continue  # Skip tiny regions\n",
    "        \n",
    "        # Compute edge ratio in the region for adaptive blending.\n",
    "        edge_ratio = np.sum(edge_mask & region_mask) / np.sum(region_mask)\n",
    "        # Adjust blend factor based on edge density (lower blend when more edges are present)\n",
    "        blend_factor = max(0.3, 1 - edge_ratio)\n",
    "        \n",
    "        if transfer_method is None:\n",
    "            # Basic tint: use the region's mean color from the source.\n",
    "            mean_color = cv2.mean(src, mask=(region_mask.astype(np.uint8) * 255))[:3]\n",
    "            mean_color = np.array(mean_color, dtype=np.uint8)\n",
    "            region_result = apply_tint_to_region(out_img, region_mask, mean_color, blend=blend_factor)\n",
    "        else:\n",
    "            # Region-based color transfer:\n",
    "            # Extract the region from both source and target images.\n",
    "            src_region = src.copy()\n",
    "            tgt_region = out_img.copy()\n",
    "            # Zero out pixels outside the region (we assume background remains unchanged).\n",
    "            src_region[~region_mask] = 0\n",
    "            tgt_region[~region_mask] = 0\n",
    "            \n",
    "            # It may help to process only the nonzero region.\n",
    "            # Here, we compute the transfer on the whole region; if necessary, you could\n",
    "            # crop to a bounding box for efficiency.\n",
    "            transferred_region = color_transfer(tgt_region, src_region, method=transfer_method)\n",
    "            # Blend the transferred region with the original target to preserve edge details.\n",
    "            region_result = out_img.copy()\n",
    "            region_result[region_mask] = cv2.addWeighted(out_img[region_mask], 1 - blend_factor,\n",
    "                                                         transferred_region[region_mask], blend_factor, 0)\n",
    "        \n",
    "        # Update the output image with the processed region.\n",
    "        out_img[region_mask] = region_result[region_mask]\n",
    "\n",
    "    return out_img\n",
    "\n",
    "#############################################\n",
    "# Example Usage\n",
    "#############################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example 2: Global PCA color transfer applied on the whole image.\n",
    "    output_global = process_image( 'input2.jpg', 'reference2.jpeg', transfer_method=\"monge_kantorovitch\", region_based_transfer=True)\n",
    "    cv2.imwrite('output_global_2.jpg', output_global)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############################################\n",
    "# Mean-Shift Segmentation\n",
    "#############################################\n",
    "\n",
    "def mean_shift_segmentation(img_bgr, sp=21, sr=51):\n",
    "    filtered = cv2.pyrMeanShiftFiltering(img_bgr, sp, sr)\n",
    "    return filtered\n",
    "\n",
    "#############################################\n",
    "# Edge Detection and Processing\n",
    "#############################################\n",
    "\n",
    "def compute_edge_mask(img_bgr, low_threshold=50, high_threshold=150, dilation_iters=1):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges_dilated = cv2.dilate(edges, kernel, iterations=dilation_iters)\n",
    "    return edges_dilated > 0\n",
    "\n",
    "#############################################\n",
    "# Region Labeling from Mean-Shift Output\n",
    "#############################################\n",
    "\n",
    "def label_regions(filtered_img):\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    labeled = label(thresh)\n",
    "    return labeled\n",
    "\n",
    "#############################################\n",
    "# Apply Tint to a Region (Basic Blend)\n",
    "#############################################\n",
    "\n",
    "def apply_tint_to_region(img_bgr, region_mask, tint_color, blend=0.5):\n",
    "    tinted = img_bgr.copy()\n",
    "    tint_img = np.full_like(img_bgr, tint_color)\n",
    "    tinted[region_mask] = cv2.addWeighted(img_bgr[region_mask], 1 - blend,\n",
    "                                          tint_img[region_mask], blend, 0)\n",
    "    return tinted\n",
    "\n",
    "#############################################\n",
    "# Color Transfer Methods\n",
    "#############################################\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    if method == \"svd\":\n",
    "        U, S, Vt = np.linalg.svd(matrix)\n",
    "        return np.dot(U, np.dot(np.diag(np.sqrt(S)), Vt))\n",
    "    elif method == \"eigen\":\n",
    "        eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "        sqrt_diag = np.diag(np.sqrt(eigvals))\n",
    "        return eigvecs @ sqrt_diag @ eigvecs.T\n",
    "    elif method == \"cholesky\":\n",
    "        return np.linalg.cholesky(matrix)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method for matrix square root\")\n",
    "\n",
    "def separable_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    scale = np.sqrt(np.diag(cov_r)) / np.sqrt(np.diag(cov_t))\n",
    "    transform = np.diag(scale)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def cholesky_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    L_t = np.linalg.cholesky(cov_t)\n",
    "    L_r = np.linalg.cholesky(cov_r)\n",
    "    transform = L_r @ np.linalg.inv(L_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def pca_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def monge_kantorovitch_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"svd\")\n",
    "    inv_sqrt_cov_t = np.linalg.inv(sqrt_cov_t)\n",
    "    mk_transform = inv_sqrt_cov_t @ sqrtm(sqrt_cov_t @ cov_r @ sqrt_cov_t, method=\"svd\") @ inv_sqrt_cov_t\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), mk_transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "# A helper to choose the transfer method\n",
    "def color_transfer(target, reference, method=\"pca\"):\n",
    "    if method == \"separable\":\n",
    "        return separable_transfer(target, reference)\n",
    "    elif method == \"cholesky\":\n",
    "        return cholesky_transfer(target, reference)\n",
    "    elif method == \"pca\":\n",
    "        return pca_transfer(target, reference)\n",
    "    elif method == \"monge_kantorovitch\":\n",
    "        return monge_kantorovitch_transfer(target, reference)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown color transfer method.\")\n",
    "\n",
    "#############################################\n",
    "# Integrated Processing Pipeline\n",
    "#############################################\n",
    "\n",
    "def process_image(src_path, tgt_path, transfer_method=None, region_based_transfer=False):\n",
    "    \"\"\"\n",
    "    Process the target image by:\n",
    "    1. Applying mean-shift segmentation.\n",
    "    2. Detecting edges.\n",
    "    3. Labeling regions.\n",
    "    4. For each region, either apply:\n",
    "         a. A basic tint (using the mean color from the source) with edge-aware blending, or\n",
    "         b. A color transfer (global or per-region) using the selected transfer method.\n",
    "    \n",
    "    Parameters:\n",
    "      transfer_method: One of \"separable\", \"cholesky\", \"pca\", \"monge_kantorovitch\".\n",
    "                       If None, the basic tint (mean blending) is used.\n",
    "      region_based_transfer: If True, apply the transfer method on each segmented region.\n",
    "                             If False, apply a global transfer to the whole image.\n",
    "    \"\"\"\n",
    "    src = cv2.imread(src_path)\n",
    "    tgt = cv2.imread(tgt_path)\n",
    "    if src is None or tgt is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # Resize source to target size if necessary\n",
    "    if src.shape != tgt.shape:\n",
    "        src = cv2.resize(src, (tgt.shape[1], tgt.shape[0]))\n",
    "\n",
    "    # Apply mean-shift segmentation and edge detection\n",
    "    ms_tgt = mean_shift_segmentation(tgt, sp=21, sr=51)\n",
    "    edge_mask = compute_edge_mask(tgt, low_threshold=50, high_threshold=150, dilation_iters=1)\n",
    "    labels = label_regions(ms_tgt)\n",
    "    props = regionprops(labels)\n",
    "    \n",
    "    out_img = tgt.copy()\n",
    "\n",
    "    # Option 1: Global color transfer\n",
    "    if transfer_method is not None and not region_based_transfer:\n",
    "        # Apply the selected color transfer to the full images.\n",
    "        out_img = color_transfer(tgt, src, method=transfer_method)\n",
    "        return out_img\n",
    "\n",
    "    # Option 2: Per-region processing (basic tint or color transfer)\n",
    "    for prop in props:\n",
    "        region_mask = (labels == prop.label)\n",
    "        if np.sum(region_mask) < 50:\n",
    "            continue  # Skip tiny regions\n",
    "        \n",
    "        # Compute edge ratio in the region for adaptive blending.\n",
    "        edge_ratio = np.sum(edge_mask & region_mask) / np.sum(region_mask)\n",
    "        # Adjust blend factor based on edge density (lower blend when more edges are present)\n",
    "        blend_factor = max(0.3, 1 - edge_ratio)\n",
    "        \n",
    "        if transfer_method is None:\n",
    "            # Basic tint: use the region's mean color from the source.\n",
    "            mean_color = cv2.mean(src, mask=(region_mask.astype(np.uint8) * 255))[:3]\n",
    "            mean_color = np.array(mean_color, dtype=np.uint8)\n",
    "            region_result = apply_tint_to_region(out_img, region_mask, mean_color, blend=blend_factor)\n",
    "        else:\n",
    "            # Region-based color transfer:\n",
    "            # Extract the region from both source and target images.\n",
    "            src_region = src.copy()\n",
    "            tgt_region = out_img.copy()\n",
    "            # Zero out pixels outside the region (we assume background remains unchanged).\n",
    "            src_region[~region_mask] = 0\n",
    "            tgt_region[~region_mask] = 0\n",
    "            \n",
    "            # It may help to process only the nonzero region.\n",
    "            # Here, we compute the transfer on the whole region; if necessary, you could\n",
    "            # crop to a bounding box for efficiency.\n",
    "            transferred_region = color_transfer(tgt_region, src_region, method=transfer_method)\n",
    "            # Blend the transferred region with the original target to preserve edge details.\n",
    "            region_result = out_img.copy()\n",
    "            region_result[region_mask] = cv2.addWeighted(out_img[region_mask], 1 - blend_factor,\n",
    "                                                         transferred_region[region_mask], blend_factor, 0)\n",
    "        \n",
    "        # Update the output image with the processed region.\n",
    "        out_img[region_mask] = region_result[region_mask]\n",
    "\n",
    "    return out_img\n",
    "\n",
    "#############################################\n",
    "# Example Usage\n",
    "#############################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example 2: Global PCA color transfer applied on the whole image.\n",
    "    output_global = process_image('reference4.jpeg', 'input4.jpg', transfer_method=\"pca\", region_based_transfer=False)\n",
    "    cv2.imwrite('output_global_4.jpg', output_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############################################\n",
    "# Mean-Shift Segmentation\n",
    "#############################################\n",
    "\n",
    "def mean_shift_segmentation(img_bgr, sp=21, sr=51):\n",
    "    filtered = cv2.pyrMeanShiftFiltering(img_bgr, sp, sr)\n",
    "    return filtered\n",
    "\n",
    "#############################################\n",
    "# Edge Detection and Processing\n",
    "#############################################\n",
    "\n",
    "def compute_edge_mask(img_bgr, low_threshold=50, high_threshold=150, dilation_iters=1):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges_dilated = cv2.dilate(edges, kernel, iterations=dilation_iters)\n",
    "    return edges_dilated > 0\n",
    "\n",
    "#############################################\n",
    "# Region Labeling from Mean-Shift Output\n",
    "#############################################\n",
    "\n",
    "def label_regions(filtered_img):\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    labeled = label(thresh)\n",
    "    return labeled\n",
    "\n",
    "#############################################\n",
    "# Apply Tint to a Region (Basic Blend)\n",
    "#############################################\n",
    "\n",
    "def apply_tint_to_region(img_bgr, region_mask, tint_color, blend=0.5):\n",
    "    tinted = img_bgr.copy()\n",
    "    tint_img = np.full_like(img_bgr, tint_color)\n",
    "    tinted[region_mask] = cv2.addWeighted(img_bgr[region_mask], 1 - blend,\n",
    "                                          tint_img[region_mask], blend, 0)\n",
    "    return tinted\n",
    "\n",
    "#############################################\n",
    "# Color Transfer Methods (Global)\n",
    "#############################################\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    if method == \"svd\":\n",
    "        U, S, Vt = np.linalg.svd(matrix)\n",
    "        return np.dot(U, np.dot(np.diag(np.sqrt(S)), Vt))\n",
    "    elif method == \"eigen\":\n",
    "        eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "        sqrt_diag = np.diag(np.sqrt(eigvals))\n",
    "        return eigvecs @ sqrt_diag @ eigvecs.T\n",
    "    elif method == \"cholesky\":\n",
    "        return np.linalg.cholesky(matrix)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method for matrix square root\")\n",
    "\n",
    "def separable_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    scale = np.sqrt(np.diag(cov_r)) / np.sqrt(np.diag(cov_t))\n",
    "    transform = np.diag(scale)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def cholesky_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    L_t = np.linalg.cholesky(cov_t)\n",
    "    L_r = np.linalg.cholesky(cov_r)\n",
    "    transform = L_r @ np.linalg.inv(L_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def pca_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "def monge_kantorovitch_transfer(target, reference):\n",
    "    target = target.astype(np.float32) / 255.0\n",
    "    reference = reference.astype(np.float32) / 255.0\n",
    "    mu_t, cov_t = compute_mean_and_cov(target)\n",
    "    mu_r, cov_r = compute_mean_and_cov(reference)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"svd\")\n",
    "    inv_sqrt_cov_t = np.linalg.inv(sqrt_cov_t)\n",
    "    mk_transform = inv_sqrt_cov_t @ sqrtm(sqrt_cov_t @ cov_r @ sqrt_cov_t, method=\"svd\") @ inv_sqrt_cov_t\n",
    "    transformed = np.dot((target.reshape(-1, 3) - mu_t), mk_transform.T) + mu_r\n",
    "    transformed = np.clip(transformed, 0, 1)\n",
    "    return (transformed.reshape(target.shape) * 255).astype(np.uint8)\n",
    "\n",
    "#############################################\n",
    "# LAB-Based PCA Transfer (Preserve Luminance)\n",
    "#############################################\n",
    "\n",
    "def pca_transfer_lab(target, reference):\n",
    "    \"\"\"\n",
    "    Applies PCA-based transfer on the chrominance (A and B) channels in LAB.\n",
    "    Luminance (L) is preserved from the target.\n",
    "    \"\"\"\n",
    "    # Convert images to LAB color space\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    ref_lab = cv2.cvtColor(reference, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    \n",
    "    # Separate L (luminance) and AB (chrominance)\n",
    "    L_t = target_lab[:, :, 0]\n",
    "    AB_t = target_lab[:, :, 1:3]\n",
    "    AB_r = ref_lab[:, :, 1:3]\n",
    "    \n",
    "    # Normalize AB channels to [0, 1]\n",
    "    AB_t /= 255.0\n",
    "    AB_r /= 255.0\n",
    "    \n",
    "    # Reshape AB channels to (num_pixels x 2)\n",
    "    AB_t_flat = AB_t.reshape(-1, 2)\n",
    "    AB_r_flat = AB_r.reshape(-1, 2)\n",
    "    \n",
    "    # Compute means and covariances for chrominance channels\n",
    "    mu_t = np.mean(AB_t_flat, axis=0)\n",
    "    mu_r = np.mean(AB_r_flat, axis=0)\n",
    "    cov_t = np.cov(AB_t_flat, rowvar=False)\n",
    "    cov_r = np.cov(AB_r_flat, rowvar=False)\n",
    "    \n",
    "    # Compute square roots of covariance matrices using eigen decomposition\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    \n",
    "    # Compute transformation matrix\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    \n",
    "    # Apply transformation to the AB channels\n",
    "    AB_transformed = ((AB_t_flat - mu_t) @ transform.T) + mu_r\n",
    "    AB_transformed = np.clip(AB_transformed, 0, 1).reshape(AB_t.shape)\n",
    "    \n",
    "    # Scale AB back to [0, 255]\n",
    "    AB_transformed = (AB_transformed * 255).astype(np.uint8)\n",
    "    \n",
    "    # Combine original L with transformed AB channels\n",
    "    L_t = np.clip(L_t, 0, 255).astype(np.uint8)\n",
    "    lab_transferred = cv2.merge((L_t, AB_transformed[:, :, 0], AB_transformed[:, :, 1]))\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    return cv2.cvtColor(lab_transferred, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "#############################################\n",
    "# Helper for Color Transfer Choice\n",
    "#############################################\n",
    "\n",
    "def color_transfer(target, reference, method=\"pca\"):\n",
    "    if method == \"separable\":\n",
    "        return separable_transfer(target, reference)\n",
    "    elif method == \"cholesky\":\n",
    "        return cholesky_transfer(target, reference)\n",
    "    elif method == \"pca\":\n",
    "        return pca_transfer(target, reference)\n",
    "    elif method == \"monge_kantorovitch\":\n",
    "        return monge_kantorovitch_transfer(target, reference)\n",
    "    elif method == \"pca_lab\":\n",
    "        return pca_transfer_lab(target, reference)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown color transfer method.\")\n",
    "\n",
    "#############################################\n",
    "# Integrated Processing Pipeline\n",
    "#############################################\n",
    "\n",
    "def process_image(src_path, tgt_path, transfer_method=None, region_based_transfer=False):\n",
    "    \"\"\"\n",
    "    Process the target image by:\n",
    "      1. Applying mean-shift segmentation.\n",
    "      2. Detecting edges.\n",
    "      3. Labeling regions.\n",
    "      4. For each region, either apply:\n",
    "             a. A basic tint (using the mean color from the source) with edge-aware blending, or\n",
    "             b. A color transfer (global or per-region) using the selected transfer method.\n",
    "    \n",
    "    Parameters:\n",
    "      transfer_method: One of \"separable\", \"cholesky\", \"pca\", \"monge_kantorovitch\", \"pca_lab\".\n",
    "                       If None, the basic tint (mean blending) is used.\n",
    "      region_based_transfer: If True, apply the transfer method on each segmented region.\n",
    "                             If False, apply a global transfer to the whole image.\n",
    "    \"\"\"\n",
    "    src = cv2.imread(src_path)\n",
    "    tgt = cv2.imread(tgt_path)\n",
    "    if src is None or tgt is None:\n",
    "        raise IOError(\"Could not load source or target image.\")\n",
    "\n",
    "    # Resize source to target size if necessary\n",
    "    if src.shape != tgt.shape:\n",
    "        src = cv2.resize(src, (tgt.shape[1], tgt.shape[0]))\n",
    "\n",
    "    # Apply mean-shift segmentation and edge detection\n",
    "    ms_tgt = mean_shift_segmentation(tgt, sp=21, sr=51)\n",
    "    edge_mask = compute_edge_mask(tgt, low_threshold=50, high_threshold=150, dilation_iters=1)\n",
    "    labels = label_regions(ms_tgt)\n",
    "    props = regionprops(labels)\n",
    "    \n",
    "    out_img = tgt.copy()\n",
    "\n",
    "    # Global color transfer\n",
    "    if transfer_method is not None and not region_based_transfer:\n",
    "        out_img = color_transfer(tgt, src, method=transfer_method)\n",
    "        return out_img\n",
    "\n",
    "    # Per-region processing (basic tint or region-based color transfer)\n",
    "    for prop in props:\n",
    "        region_mask = (labels == prop.label)\n",
    "        if np.sum(region_mask) < 50:\n",
    "            continue  # Skip tiny regions\n",
    "        \n",
    "        # Compute edge ratio in the region for adaptive blending.\n",
    "        edge_ratio = np.sum(edge_mask & region_mask) / np.sum(region_mask)\n",
    "        blend_factor = max(0.3, 1 - edge_ratio)\n",
    "        \n",
    "        if transfer_method is None:\n",
    "            # Basic tint: use the region's mean color from the source.\n",
    "            mean_color = cv2.mean(src, mask=(region_mask.astype(np.uint8) * 255))[:3]\n",
    "            mean_color = np.array(mean_color, dtype=np.uint8)\n",
    "            region_result = apply_tint_to_region(out_img, region_mask, mean_color, blend=blend_factor)\n",
    "        else:\n",
    "            # Region-based color transfer:\n",
    "            src_region = src.copy()\n",
    "            tgt_region = out_img.copy()\n",
    "            src_region[~region_mask] = 0\n",
    "            tgt_region[~region_mask] = 0\n",
    "            \n",
    "            transferred_region = color_transfer(tgt_region, src_region, method=transfer_method)\n",
    "            region_result = out_img.copy()\n",
    "            region_result[region_mask] = cv2.addWeighted(out_img[region_mask], 1 - blend_factor,\n",
    "                                                         transferred_region[region_mask], blend_factor, 0)\n",
    "        \n",
    "        # Update output image for this region\n",
    "        out_img[region_mask] = region_result[region_mask]\n",
    "\n",
    "    return out_img\n",
    "\n",
    "#############################################\n",
    "# Example Usage\n",
    "#############################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example: Global LAB-based PCA color transfer applied on the whole image.\n",
    "    output_global = process_image('input4.jpg', 'reference4.jpeg', transfer_method=\"pca_lab\", region_based_transfer=False)\n",
    "    cv2.imwrite('output_global_2.jpg', output_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "#############################################\n",
    "# Processing Functions (Example: LAB-based PCA Transfer)\n",
    "#############################################\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    # Simple square-root using eigen decomposition.\n",
    "    eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "    return eigvecs @ np.diag(np.sqrt(eigvals)) @ eigvecs.T\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def pca_transfer_lab(target, reference):\n",
    "    \"\"\"\n",
    "    Applies PCA-based transfer on the chrominance (A and B) channels in LAB.\n",
    "    Luminance (L) is preserved from the target.\n",
    "    \"\"\"\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    ref_lab = cv2.cvtColor(reference, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    L_t = target_lab[:, :, 0]\n",
    "    AB_t = target_lab[:, :, 1:3]\n",
    "    AB_r = ref_lab[:, :, 1:3]\n",
    "    AB_t /= 255.0\n",
    "    AB_r /= 255.0\n",
    "    AB_t_flat = AB_t.reshape(-1, 2)\n",
    "    AB_r_flat = AB_r.reshape(-1, 2)\n",
    "    mu_t = np.mean(AB_t_flat, axis=0)\n",
    "    mu_r = np.mean(AB_r_flat, axis=0)\n",
    "    cov_t = np.cov(AB_t_flat, rowvar=False)\n",
    "    cov_r = np.cov(AB_r_flat, rowvar=False)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    AB_transformed = ((AB_t_flat - mu_t) @ transform.T) + mu_r\n",
    "    AB_transformed = np.clip(AB_transformed, 0, 1).reshape(AB_t.shape)\n",
    "    AB_transformed = (AB_transformed * 255).astype(np.uint8)\n",
    "    L_t = np.clip(L_t, 0, 255).astype(np.uint8)\n",
    "    lab_transferred = cv2.merge((L_t, AB_transformed[:, :, 0], AB_transformed[:, :, 1]))\n",
    "    return cv2.cvtColor(lab_transferred, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def process_sequential(target, ref_list):\n",
    "    \"\"\"\n",
    "    Sequentially applies the color transfer.\n",
    "    target: initial target image (BGR).\n",
    "    ref_list: list of reference images (BGR).\n",
    "    Returns a list of tuples: (label, image) with intermediate outputs.\n",
    "    \"\"\"\n",
    "    results = [(\"Target\", target.copy())]\n",
    "    current = target.copy()\n",
    "    for i, ref in enumerate(ref_list, start=1):\n",
    "        # Resize reference if necessary.\n",
    "        if ref.shape != current.shape:\n",
    "            ref = cv2.resize(ref, (current.shape[1], current.shape[0]))\n",
    "        current = pca_transfer_lab(current, ref)\n",
    "        results.append((f\"Output {i}\", current.copy()))\n",
    "    return results\n",
    "\n",
    "#############################################\n",
    "# Advanced Tkinter UI\n",
    "#############################################\n",
    "\n",
    "class ColorTransferApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Sequential Color Transfer\")\n",
    "        self.geometry(\"1000x700\")\n",
    "        \n",
    "        self.target_img = None       # BGR numpy array\n",
    "        self.ref_imgs = []           # List of BGR numpy arrays\n",
    "        self.intermediate_results = []  # List of (label, BGR image)\n",
    "        \n",
    "        self.create_widgets()\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        # Top frame for image selection\n",
    "        top_frame = tk.Frame(self)\n",
    "        top_frame.pack(padx=10, pady=10, fill=tk.X)\n",
    "        \n",
    "        self.btn_load_target = tk.Button(top_frame, text=\"Load Target Image\", command=self.load_target)\n",
    "        self.btn_load_target.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.btn_load_refs = tk.Button(top_frame, text=\"Load Reference Images\", command=self.load_references)\n",
    "        self.btn_load_refs.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.btn_run = tk.Button(top_frame, text=\"Run Sequential Transfer\", command=self.run_transfer)\n",
    "        self.btn_run.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.btn_save = tk.Button(top_frame, text=\"Save Final Output\", command=self.save_final)\n",
    "        self.btn_save.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Middle frame for displaying target and reference thumbnails\n",
    "        mid_frame = tk.Frame(self)\n",
    "        mid_frame.pack(padx=10, pady=5, fill=tk.X)\n",
    "        \n",
    "        self.lbl_target = tk.Label(mid_frame, text=\"Target Image Not Loaded\", bd=2, relief=tk.SOLID, width=200, height=200)\n",
    "        self.lbl_target.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        ref_frame = tk.Frame(mid_frame)\n",
    "        ref_frame.pack(side=tk.LEFT, padx=10, fill=tk.Y)\n",
    "        \n",
    "        tk.Label(ref_frame, text=\"Reference Images\").pack()\n",
    "        self.lst_refs = tk.Listbox(ref_frame, width=30, height=10)\n",
    "        self.lst_refs.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.ref_thumbs = []  # List to store thumbnail PhotoImage objects\n",
    "        \n",
    "        # Scrollable frame for intermediate outputs\n",
    "        output_frame = tk.Frame(self)\n",
    "        output_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        canvas = tk.Canvas(output_frame)\n",
    "        canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        scrollbar = tk.Scrollbar(output_frame, orient=\"horizontal\", command=canvas.xview)\n",
    "        scrollbar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        canvas.configure(xscrollcommand=scrollbar.set)\n",
    "        canvas.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "        \n",
    "        self.results_frame = tk.Frame(canvas)\n",
    "        canvas.create_window((0, 0), window=self.results_frame, anchor=\"nw\")\n",
    "    \n",
    "    def load_target(self):\n",
    "        path = filedialog.askopenfilename(title=\"Select Target Image\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if path:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                messagebox.showerror(\"Error\", \"Failed to load target image.\")\n",
    "                return\n",
    "            self.target_img = img\n",
    "            self.display_image(self.lbl_target, img)\n",
    "    \n",
    "    def load_references(self):\n",
    "        paths = filedialog.askopenfilenames(title=\"Select Reference Images\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if paths:\n",
    "            self.ref_imgs = []\n",
    "            self.lst_refs.delete(0, tk.END)\n",
    "            self.ref_thumbs = []\n",
    "            for path in paths:\n",
    "                img = cv2.imread(path)\n",
    "                if img is not None:\n",
    "                    self.ref_imgs.append(img)\n",
    "                    # Create thumbnail for display\n",
    "                    thumb = self.create_thumbnail(img, 100, 100)\n",
    "                    self.ref_thumbs.append(thumb)\n",
    "                    self.lst_refs.insert(tk.END, path.split(\"/\")[-1])\n",
    "    \n",
    "    def run_transfer(self):\n",
    "        if self.target_img is None:\n",
    "            messagebox.showwarning(\"No Target\", \"Please load a target image.\")\n",
    "            return\n",
    "        if not self.ref_imgs:\n",
    "            messagebox.showwarning(\"No References\", \"Please load at least one reference image.\")\n",
    "            return\n",
    "        \n",
    "        self.intermediate_results = process_sequential(self.target_img, self.ref_imgs)\n",
    "        self.display_intermediate_results()\n",
    "    \n",
    "    def display_intermediate_results(self):\n",
    "        # Clear previous results in the results_frame.\n",
    "        for widget in self.results_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        for label_text, img in self.intermediate_results:\n",
    "            frame = tk.Frame(self.results_frame, bd=2, relief=tk.RIDGE)\n",
    "            frame.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "            tk.Label(frame, text=label_text).pack()\n",
    "            img_label = tk.Label(frame)\n",
    "            img_label.pack()\n",
    "            self.display_image(img_label, img, width=200, height=200)\n",
    "    \n",
    "    def save_final(self):\n",
    "        if not self.intermediate_results:\n",
    "            messagebox.showinfo(\"No Output\", \"No output available to save.\")\n",
    "            return\n",
    "        final_label, final_img = self.intermediate_results[-1]\n",
    "        path = filedialog.asksaveasfilename(title=\"Save Final Output\", defaultextension=\".jpg\",\n",
    "                                              filetypes=[(\"JPEG Files\", \"*.jpg\"), (\"PNG Files\", \"*.png\")])\n",
    "        if path:\n",
    "            cv2.imwrite(path, final_img)\n",
    "            messagebox.showinfo(\"Saved\", f\"Final output saved to {path}\")\n",
    "    \n",
    "    def display_image(self, label, cv_img, width=None, height=None):\n",
    "        # Convert BGR to RGB and then to PIL image.\n",
    "        rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb)\n",
    "        if width and height:\n",
    "            pil_img.thumbnail((width, height))\n",
    "        else:\n",
    "            pil_img.thumbnail((200, 200))\n",
    "        imgtk = ImageTk.PhotoImage(pil_img)\n",
    "        label.configure(image=imgtk)\n",
    "        label.image = imgtk  # keep a reference\n",
    "        \n",
    "    def create_thumbnail(self, cv_img, width, height):\n",
    "        rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb)\n",
    "        pil_img.thumbnail((width, height))\n",
    "        return ImageTk.PhotoImage(pil_img)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = ColorTransferApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "#############################################\n",
    "# Processing Functions (Example: LAB-based PCA Transfer)\n",
    "#############################################\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    # Simple square-root using eigen decomposition.\n",
    "    eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "    return eigvecs @ np.diag(np.sqrt(eigvals)) @ eigvecs.T\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def pca_transfer_lab(target, reference):\n",
    "    \"\"\"\n",
    "    Applies PCA-based transfer on the chrominance (A and B) channels in LAB.\n",
    "    Luminance (L) is preserved from the target.\n",
    "    \"\"\"\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    ref_lab = cv2.cvtColor(reference, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    L_t = target_lab[:, :, 0]\n",
    "    AB_t = target_lab[:, :, 1:3]\n",
    "    AB_r = ref_lab[:, :, 1:3]\n",
    "    AB_t /= 255.0\n",
    "    AB_r /= 255.0\n",
    "    AB_t_flat = AB_t.reshape(-1, 2)\n",
    "    AB_r_flat = AB_r.reshape(-1, 2)\n",
    "    mu_t = np.mean(AB_t_flat, axis=0)\n",
    "    mu_r = np.mean(AB_r_flat, axis=0)\n",
    "    cov_t = np.cov(AB_t_flat, rowvar=False)\n",
    "    cov_r = np.cov(AB_r_flat, rowvar=False)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    AB_transformed = ((AB_t_flat - mu_t) @ transform.T) + mu_r\n",
    "    AB_transformed = np.clip(AB_transformed, 0, 1).reshape(AB_t.shape)\n",
    "    AB_transformed = (AB_transformed * 255).astype(np.uint8)\n",
    "    L_t = np.clip(L_t, 0, 255).astype(np.uint8)\n",
    "    lab_transferred = cv2.merge((L_t, AB_transformed[:, :, 0], AB_transformed[:, :, 1]))\n",
    "    return cv2.cvtColor(lab_transferred, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def process_sequential(target, ref_list):\n",
    "    \"\"\"\n",
    "    Sequentially applies the color transfer.\n",
    "    target: initial target image (BGR).\n",
    "    ref_list: list of reference images (BGR) in the desired order.\n",
    "    Returns a list of tuples: (label, image) with intermediate outputs.\n",
    "    \"\"\"\n",
    "    results = [(\"Target\", target.copy())]\n",
    "    current = target.copy()\n",
    "    for i, ref in enumerate(ref_list, start=1):\n",
    "        if ref.shape != current.shape:\n",
    "            ref = cv2.resize(ref, (current.shape[1], current.shape[0]))\n",
    "        current = pca_transfer_lab(current, ref)\n",
    "        results.append((f\"Output {i}\", current.copy()))\n",
    "    return results\n",
    "\n",
    "#############################################\n",
    "# Advanced Tkinter UI with Reference Ordering\n",
    "#############################################\n",
    "\n",
    "class ColorTransferApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Sequential Color Transfer\")\n",
    "        self.geometry(\"1100x750\")\n",
    "        \n",
    "        self.target_img = None        # BGR numpy array for target image\n",
    "        self.ref_imgs = []            # List of BGR numpy arrays for reference images\n",
    "        self.ref_files = []           # Corresponding file names for references\n",
    "        self.intermediate_results = []  # List of (label, BGR image)\n",
    "        \n",
    "        self.create_widgets()\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        # Top frame for buttons\n",
    "        top_frame = tk.Frame(self)\n",
    "        top_frame.pack(padx=10, pady=10, fill=tk.X)\n",
    "        \n",
    "        tk.Button(top_frame, text=\"Load Target Image\", command=self.load_target).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Load Reference Images\", command=self.load_references).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Run Sequential Transfer\", command=self.run_transfer).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Save Final Output\", command=self.save_final).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Middle frame for target and reference order\n",
    "        mid_frame = tk.Frame(self)\n",
    "        mid_frame.pack(padx=10, pady=5, fill=tk.X)\n",
    "        \n",
    "        # Target image display\n",
    "        self.lbl_target = tk.Label(mid_frame, text=\"Target Image Not Loaded\", bd=2, relief=tk.SOLID, width=200, height=200)\n",
    "        self.lbl_target.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Frame for reference list with reordering buttons\n",
    "        ref_list_frame = tk.Frame(mid_frame)\n",
    "        ref_list_frame.pack(side=tk.LEFT, padx=10, fill=tk.Y)\n",
    "        \n",
    "        tk.Label(ref_list_frame, text=\"Reference Images (Order)\").pack()\n",
    "        self.lst_refs = tk.Listbox(ref_list_frame, width=40, height=10)\n",
    "        self.lst_refs.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "        \n",
    "        btns_frame = tk.Frame(ref_list_frame)\n",
    "        btns_frame.pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(btns_frame, text=\"Move Up\", command=self.move_up).pack(pady=2)\n",
    "        tk.Button(btns_frame, text=\"Move Down\", command=self.move_down).pack(pady=2)\n",
    "        \n",
    "        # Scrollable frame for intermediate outputs (horizontal)\n",
    "        output_frame = tk.Frame(self)\n",
    "        output_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        self.out_canvas = tk.Canvas(output_frame)\n",
    "        self.out_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        out_scrollbar = tk.Scrollbar(output_frame, orient=\"horizontal\", command=self.out_canvas.xview)\n",
    "        out_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        self.out_canvas.configure(xscrollcommand=out_scrollbar.set)\n",
    "        self.results_frame = tk.Frame(self.out_canvas)\n",
    "        self.out_canvas.create_window((0, 0), window=self.results_frame, anchor=\"nw\")\n",
    "        self.results_frame.bind(\"<Configure>\", lambda e: self.out_canvas.configure(scrollregion=self.out_canvas.bbox(\"all\")))\n",
    "    \n",
    "    def load_target(self):\n",
    "        path = filedialog.askopenfilename(title=\"Select Target Image\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if path:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                messagebox.showerror(\"Error\", \"Failed to load target image.\")\n",
    "                return\n",
    "            self.target_img = img\n",
    "            self.display_image(self.lbl_target, img, 200, 200)\n",
    "    \n",
    "    def load_references(self):\n",
    "        paths = filedialog.askopenfilenames(title=\"Select Reference Images\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if paths:\n",
    "            self.ref_imgs = []\n",
    "            self.ref_files = []\n",
    "            self.lst_refs.delete(0, tk.END)\n",
    "            for path in paths:\n",
    "                img = cv2.imread(path)\n",
    "                if img is not None:\n",
    "                    self.ref_imgs.append(img)\n",
    "                    self.ref_files.append(path.split(\"/\")[-1])\n",
    "                    self.lst_refs.insert(tk.END, path.split(\"/\")[-1])\n",
    "    \n",
    "    def move_up(self):\n",
    "        # Moves the selected item up in the list\n",
    "        selected = self.lst_refs.curselection()\n",
    "        if not selected:\n",
    "            return\n",
    "        index = selected[0]\n",
    "        if index == 0:\n",
    "            return\n",
    "        # Swap in listbox\n",
    "        item_text = self.lst_refs.get(index)\n",
    "        self.lst_refs.delete(index)\n",
    "        self.lst_refs.insert(index - 1, item_text)\n",
    "        self.lst_refs.selection_set(index - 1)\n",
    "        # Swap in our reference lists\n",
    "        self.ref_imgs[index], self.ref_imgs[index - 1] = self.ref_imgs[index - 1], self.ref_imgs[index]\n",
    "        self.ref_files[index], self.ref_files[index - 1] = self.ref_files[index - 1], self.ref_files[index]\n",
    "    \n",
    "    def move_down(self):\n",
    "        # Moves the selected item down in the list\n",
    "        selected = self.lst_refs.curselection()\n",
    "        if not selected:\n",
    "            return\n",
    "        index = selected[0]\n",
    "        if index == self.lst_refs.size() - 1:\n",
    "            return\n",
    "        item_text = self.lst_refs.get(index)\n",
    "        self.lst_refs.delete(index)\n",
    "        self.lst_refs.insert(index + 1, item_text)\n",
    "        self.lst_refs.selection_set(index + 1)\n",
    "        # Swap in our reference lists\n",
    "        self.ref_imgs[index], self.ref_imgs[index + 1] = self.ref_imgs[index + 1], self.ref_imgs[index]\n",
    "        self.ref_files[index], self.ref_files[index + 1] = self.ref_files[index + 1], self.ref_files[index]\n",
    "    \n",
    "    def run_transfer(self):\n",
    "        if self.target_img is None:\n",
    "            messagebox.showwarning(\"No Target\", \"Please load a target image.\")\n",
    "            return\n",
    "        if not self.ref_imgs:\n",
    "            messagebox.showwarning(\"No References\", \"Please load at least one reference image.\")\n",
    "            return\n",
    "        \n",
    "        # Process sequentially in the order from the listbox.\n",
    "        self.intermediate_results = process_sequential(self.target_img, self.ref_imgs)\n",
    "        self.display_intermediate_results()\n",
    "    \n",
    "    def display_intermediate_results(self):\n",
    "        # Clear previous results\n",
    "        for widget in self.results_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        for label_text, img in self.intermediate_results:\n",
    "            frame = tk.Frame(self.results_frame, bd=2, relief=tk.RIDGE)\n",
    "            frame.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "            tk.Label(frame, text=label_text).pack()\n",
    "            img_label = tk.Label(frame)\n",
    "            img_label.pack()\n",
    "            self.display_image(img_label, img, 200, 200)\n",
    "    \n",
    "    def save_final(self):\n",
    "        if not self.intermediate_results:\n",
    "            messagebox.showinfo(\"No Output\", \"No output available to save.\")\n",
    "            return\n",
    "        final_label, final_img = self.intermediate_results[-1]\n",
    "        path = filedialog.asksaveasfilename(title=\"Save Final Output\", defaultextension=\".jpg\",\n",
    "                                              filetypes=[(\"JPEG Files\", \"*.jpg\"), (\"PNG Files\", \"*.png\")])\n",
    "        if path:\n",
    "            cv2.imwrite(path, final_img)\n",
    "            messagebox.showinfo(\"Saved\", f\"Final output saved to {path}\")\n",
    "    \n",
    "    def display_image(self, label, cv_img, width, height):\n",
    "        # Convert BGR to RGB, then to PIL image and display.\n",
    "        rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb)\n",
    "        pil_img.thumbnail((width, height))\n",
    "        imgtk = ImageTk.PhotoImage(pil_img)\n",
    "        label.configure(image=imgtk)\n",
    "        label.image = imgtk  # keep a reference\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = ColorTransferApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "#############################################\n",
    "# Processing Functions (Example: LAB-based PCA Transfer)\n",
    "#############################################\n",
    "\n",
    "def sqrtm(matrix, method=\"svd\"):\n",
    "    # Simple square-root using eigen decomposition.\n",
    "    eigvals, eigvecs = np.linalg.eigh(matrix)\n",
    "    return eigvecs @ np.diag(np.sqrt(eigvals)) @ eigvecs.T\n",
    "\n",
    "def compute_mean_and_cov(image):\n",
    "    reshaped = image.reshape(-1, 3).astype(np.float32)\n",
    "    mean = np.mean(reshaped, axis=0)\n",
    "    cov = np.cov(reshaped, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "def pca_transfer_lab(target, reference):\n",
    "    \"\"\"\n",
    "    Applies PCA-based transfer on the chrominance (A and B) channels in LAB.\n",
    "    Luminance (L) is preserved from the target.\n",
    "    \"\"\"\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    ref_lab = cv2.cvtColor(reference, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    L_t = target_lab[:, :, 0]\n",
    "    AB_t = target_lab[:, :, 1:3]\n",
    "    AB_r = ref_lab[:, :, 1:3]\n",
    "    AB_t /= 255.0\n",
    "    AB_r /= 255.0\n",
    "    AB_t_flat = AB_t.reshape(-1, 2)\n",
    "    AB_r_flat = AB_r.reshape(-1, 2)\n",
    "    mu_t = np.mean(AB_t_flat, axis=0)\n",
    "    mu_r = np.mean(AB_r_flat, axis=0)\n",
    "    cov_t = np.cov(AB_t_flat, rowvar=False)\n",
    "    cov_r = np.cov(AB_r_flat, rowvar=False)\n",
    "    sqrt_cov_t = sqrtm(cov_t, method=\"eigen\")\n",
    "    sqrt_cov_r = sqrtm(cov_r, method=\"eigen\")\n",
    "    transform = sqrt_cov_r @ np.linalg.inv(sqrt_cov_t)\n",
    "    AB_transformed = ((AB_t_flat - mu_t) @ transform.T) + mu_r\n",
    "    AB_transformed = np.clip(AB_transformed, 0, 1).reshape(AB_t.shape)\n",
    "    AB_transformed = (AB_transformed * 255).astype(np.uint8)\n",
    "    L_t = np.clip(L_t, 0, 255).astype(np.uint8)\n",
    "    lab_transferred = cv2.merge((L_t, AB_transformed[:, :, 0], AB_transformed[:, :, 1]))\n",
    "    return cv2.cvtColor(lab_transferred, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def process_sequential(target, ref_list):\n",
    "    \"\"\"\n",
    "    Sequentially applies the color transfer.\n",
    "    target: initial target image (BGR).\n",
    "    ref_list: list of reference images (BGR) in the desired order.\n",
    "    Returns a list of tuples: (label, image) with intermediate outputs.\n",
    "    \"\"\"\n",
    "    results = [(\"Target\", target.copy())]\n",
    "    current = target.copy()\n",
    "    for i, ref in enumerate(ref_list, start=1):\n",
    "        if ref.shape != current.shape:\n",
    "            ref = cv2.resize(ref, (current.shape[1], current.shape[0]))\n",
    "        current = pca_transfer_lab(current, ref)\n",
    "        results.append((f\"Output {i}\", current.copy()))\n",
    "    return results\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Utility / Processing Functions\n",
    "#############################################\n",
    "\n",
    "def cv2_to_tk(cv_img, maxsize=(500,500)):\n",
    "    rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    pil_img.thumbnail(maxsize)\n",
    "    return ImageTk.PhotoImage(pil_img)\n",
    "\n",
    "def create_polygon_mask(points, img_shape, disp_dims):\n",
    "    \"\"\"\n",
    "    Converts polygon points from canvas coordinates to image coordinates.\n",
    "    disp_dims: (display_width, display_height)\n",
    "    img_shape: (img_height, img_width)\n",
    "    \"\"\"\n",
    "    disp_w, disp_h = disp_dims\n",
    "    img_h, img_w = img_shape\n",
    "    scale_x = img_w / disp_w\n",
    "    scale_y = img_h / disp_h\n",
    "    scaled_points = [(int(x * scale_x), int(y * scale_y)) for (x, y) in points]\n",
    "    mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "    pts = np.array(scaled_points, np.int32).reshape((-1, 1, 2))\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "    return mask.astype(bool)\n",
    "\n",
    "def get_top_colors(image, k=10):\n",
    "    \"\"\"\n",
    "    Uses KMeans to extract top k colors from the image.\n",
    "    Returns a list of colors as lists [B, G, R]. If k-means fails to find enough clusters,\n",
    "    returns the unique colors found.\n",
    "    \"\"\"\n",
    "    Z = image.reshape((-1, 3)).astype(np.float32)\n",
    "    try:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(Z)\n",
    "        centers = kmeans.cluster_centers_.astype(np.uint8).tolist()\n",
    "        return centers\n",
    "    except Exception as e:\n",
    "        unique_colors = np.unique(Z, axis=0)\n",
    "        return unique_colors.tolist()\n",
    "\n",
    "def create_feathered_alpha(mask, feather=15):\n",
    "    \"\"\"\n",
    "    Computes a smooth alpha mask using a distance transform.\n",
    "    \"\"\"\n",
    "    mask_uint = mask.astype(np.uint8)\n",
    "    inv_mask = cv2.bitwise_not(mask_uint)\n",
    "    dist = cv2.distanceTransform(inv_mask, cv2.DIST_L2, 5)\n",
    "    if np.any(mask_uint == 255):\n",
    "        max_val = np.max(dist[mask_uint == 255])\n",
    "    else:\n",
    "        max_val = 1\n",
    "    alpha = 1 - (dist / (max_val + 1e-5))\n",
    "    alpha = cv2.GaussianBlur(alpha, (feather, feather), 0)\n",
    "    return np.clip(alpha, 0, 1)\n",
    "\n",
    "def apply_tint_feathering(img_bgr, mask, tint_color, blend=0.6, feather=15):\n",
    "    \"\"\"\n",
    "    Blends tint_color into img_bgr over the region defined by mask,\n",
    "    using a feathered alpha for smooth transitions.\n",
    "    \"\"\"\n",
    "    alpha = create_feathered_alpha(mask, feather=feather)\n",
    "    tint_img = np.full_like(img_bgr, tint_color, dtype=np.float32)\n",
    "    img_float = img_bgr.astype(np.float32)\n",
    "    blended = (1 - blend * alpha[..., None]) * img_float + (blend * alpha[..., None]) * tint_img\n",
    "    return np.clip(blended, 0, 255).astype(np.uint8)\n",
    "\n",
    "def compute_mean_color(img_bgr):\n",
    "    \"\"\"\n",
    "    Computes the mean [B, G, R] of the image.\n",
    "    \"\"\"\n",
    "    return np.mean(img_bgr.reshape(-1,3), axis=0).tolist()\n",
    "\n",
    "def apply_local_mapping(target_img, target_mask, mapping, threshold=40):\n",
    "    \"\"\"\n",
    "    For each pixel in target_img within target_mask, if its color is close to one of the keys in mapping,\n",
    "    then blend that pixel toward the mapped color.\n",
    "    'mapping' is a dict with keys and values as tuples: {target_color: ref_color}.\n",
    "    \"\"\"\n",
    "    out = target_img.copy().astype(np.float32)\n",
    "    indices = np.where(target_mask)\n",
    "    for y, x in zip(*indices):\n",
    "        pixel = target_img[y, x].tolist()\n",
    "        for t_color, r_color in mapping.items():\n",
    "            d = np.linalg.norm(np.array(pixel, dtype=np.float32) - np.array(t_color, dtype=np.float32))\n",
    "            if d < threshold:\n",
    "                w = 1 - (d / threshold)\n",
    "                new_val = (1 - w) * np.array(pixel) + w * np.array(r_color)\n",
    "                out[y, x] = new_val\n",
    "                break\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "#############################################\n",
    "# Interactive UI Application\n",
    "#############################################\n",
    "\n",
    "class InteractiveLocalMappingApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Interactive Local Color Mapping\")\n",
    "        self.geometry(\"1400x900\")\n",
    "        \n",
    "        # Images (BGR)\n",
    "        self.target_img = None\n",
    "        self.ref_img = None\n",
    "        self.processed_img = None  # after global transfer\n",
    "        \n",
    "        # Polygons (canvas coordinates)\n",
    "        self.target_poly_points = []\n",
    "        self.ref_poly_points = []\n",
    "        self.target_poly_id = None\n",
    "        self.ref_poly_id = None\n",
    "        \n",
    "        # Displayed dimensions (for scaling)\n",
    "        self.target_disp_dims = None\n",
    "        self.ref_disp_dims = None\n",
    "        \n",
    "        # Local masks\n",
    "        self.target_mask = None\n",
    "        self.ref_mask = None\n",
    "        \n",
    "        # Dominant colors extracted from local regions.\n",
    "        self.target_local_colors = []\n",
    "        self.ref_local_colors = []\n",
    "        \n",
    "        # Mapping dictionary: keys and values as tuples: (target_color) -> (ref_color)\n",
    "        self.mapping = {}\n",
    "        \n",
    "        # Temporary storage for mapping: when selecting, store target color first.\n",
    "        self.temp_target_color = None\n",
    "        \n",
    "        self.create_widgets()\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        top_frame = tk.Frame(self)\n",
    "        top_frame.pack(padx=10, pady=5, fill=tk.X)\n",
    "        \n",
    "        tk.Button(top_frame, text=\"Load Target Image\", command=self.load_target).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Load Reference Image\", command=self.load_reference).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Apply Global Transfer\", command=self.apply_global_transfer).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Finish Target Polygon\", command=self.finish_target_polygon).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Finish Reference Polygon\", command=self.finish_ref_polygon).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Extract Local Colors\", command=self.extract_local_colors).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(top_frame, text=\"Apply Local Mapping\", command=self.apply_local_mapping).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        main_frame = tk.Frame(self)\n",
    "        main_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Left: Target canvas for polygon selection.\n",
    "        target_frame = tk.Frame(main_frame)\n",
    "        target_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "        tk.Label(target_frame, text=\"Target Image\").pack()\n",
    "        self.target_canvas = tk.Canvas(target_frame, bg=\"gray\", width=600, height=600)\n",
    "        self.target_canvas.pack()\n",
    "        self.target_canvas.bind(\"<Button-1>\", self.on_target_click)\n",
    "        \n",
    "        # Right: Reference canvas for polygon selection.\n",
    "        ref_frame = tk.Frame(main_frame)\n",
    "        ref_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "        tk.Label(ref_frame, text=\"Reference Image\").pack()\n",
    "        self.ref_canvas = tk.Canvas(ref_frame, bg=\"gray\", width=600, height=600)\n",
    "        self.ref_canvas.pack()\n",
    "        self.ref_canvas.bind(\"<Button-1>\", self.on_ref_click)\n",
    "        \n",
    "        # Bottom: Local palettes and mapping display.\n",
    "        bottom_frame = tk.Frame(self)\n",
    "        bottom_frame.pack(padx=10, pady=5, fill=tk.X)\n",
    "        \n",
    "        tk.Label(bottom_frame, text=\"Target Local Colors:\").grid(row=0, column=0, sticky=\"w\")\n",
    "        self.target_palette_frame = tk.Frame(bottom_frame)\n",
    "        self.target_palette_frame.grid(row=1, column=0, padx=5)\n",
    "        \n",
    "        tk.Label(bottom_frame, text=\"Reference Local Colors:\").grid(row=0, column=1, sticky=\"w\")\n",
    "        self.ref_palette_frame = tk.Frame(bottom_frame)\n",
    "        self.ref_palette_frame.grid(row=1, column=1, padx=5)\n",
    "        \n",
    "        tk.Label(bottom_frame, text=\"Mappings (click target then reference):\").grid(row=0, column=2, sticky=\"w\")\n",
    "        self.mapping_frame = tk.Frame(bottom_frame)\n",
    "        self.mapping_frame.grid(row=1, column=2, padx=5)\n",
    "        \n",
    "        self.status_label = tk.Label(self, text=\"Load images to begin...\", bd=1, relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_label.pack(fill=tk.X)\n",
    "    \n",
    "    def load_target(self):\n",
    "        path = filedialog.askopenfilename(title=\"Select Target Image\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if path:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                messagebox.showerror(\"Error\", \"Failed to load target image.\")\n",
    "                return\n",
    "            self.target_img = img\n",
    "            self.processed_img = img.copy()\n",
    "            self.display_on_canvas(self.target_canvas, self.processed_img)\n",
    "            self.target_disp_dims = (self.target_canvas.winfo_width(), self.target_canvas.winfo_height())\n",
    "            self.target_poly_points = []\n",
    "            if self.target_poly_id:\n",
    "                self.target_canvas.delete(self.target_poly_id)\n",
    "                self.target_poly_id = None\n",
    "            self.status_label.config(text=\"Target image loaded. Now load reference image.\")\n",
    "    \n",
    "    def load_reference(self):\n",
    "        path = filedialog.askopenfilename(title=\"Select Reference Image\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "        if path:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                messagebox.showerror(\"Error\", \"Failed to load reference image.\")\n",
    "                return\n",
    "            self.ref_img = img\n",
    "            self.display_on_canvas(self.ref_canvas, self.ref_img)\n",
    "            self.ref_disp_dims = (self.ref_canvas.winfo_width(), self.ref_canvas.winfo_height())\n",
    "            self.status_label.config(text=\"Reference image loaded. Click 'Apply Global Transfer' when ready.\")\n",
    "    \n",
    "    def apply_global_transfer(self):\n",
    "        if self.target_img is None or self.ref_img is None:\n",
    "            messagebox.showwarning(\"Missing Images\", \"Please load both target and reference images.\")\n",
    "            return\n",
    "        self.processed_img = pca_transfer_lab(self.target_img, self.ref_img)\n",
    "        self.display_on_canvas(self.target_canvas, self.processed_img)\n",
    "        self.status_label.config(text=\"Global transfer applied. Now draw polygons on both images.\")\n",
    "    \n",
    "    def on_target_click(self, event):\n",
    "        self.target_poly_points.append((event.x, event.y))\n",
    "        r = 3\n",
    "        self.target_canvas.create_oval(event.x - r, event.y - r, event.x + r, event.y + r, fill=\"red\")\n",
    "        if self.target_poly_points:\n",
    "            if self.target_poly_id:\n",
    "                self.target_canvas.delete(self.target_poly_id)\n",
    "            self.target_poly_id = self.target_canvas.create_polygon(self.target_poly_points, outline=\"red\", fill=\"\", width=2)\n",
    "            self.status_label.config(text=f\"Target polygon: {self.target_poly_points}\")\n",
    "    \n",
    "    def on_ref_click(self, event):\n",
    "        self.ref_poly_points.append((event.x, event.y))\n",
    "        r = 3\n",
    "        self.ref_canvas.create_oval(event.x - r, event.y - r, event.x + r, event.y + r, fill=\"blue\")\n",
    "        if self.ref_poly_points:\n",
    "            if self.ref_poly_id:\n",
    "                self.ref_canvas.delete(self.ref_poly_id)\n",
    "            self.ref_poly_id = self.ref_canvas.create_polygon(self.ref_poly_points, outline=\"blue\", fill=\"\", width=2)\n",
    "            self.status_label.config(text=f\"Reference polygon: {self.ref_poly_points}\")\n",
    "    \n",
    "    def finish_target_polygon(self):\n",
    "        if len(self.target_poly_points) < 3:\n",
    "            messagebox.showwarning(\"Insufficient Points\", \"Please select at least 3 points on the target image.\")\n",
    "            return\n",
    "        self.status_label.config(text=\"Target polygon finished.\")\n",
    "    \n",
    "    def finish_ref_polygon(self):\n",
    "        if len(self.ref_poly_points) < 3:\n",
    "            messagebox.showwarning(\"Insufficient Points\", \"Please select at least 3 points on the reference image.\")\n",
    "            return\n",
    "        self.status_label.config(text=\"Reference polygon finished.\")\n",
    "    \n",
    "    def extract_local_colors(self):\n",
    "        if len(self.target_poly_points) < 3 or len(self.ref_poly_points) < 3:\n",
    "            messagebox.showwarning(\"Missing Polygon\", \"Please finish drawing polygons on both images.\")\n",
    "            return\n",
    "        self.target_mask = create_polygon_mask(self.target_poly_points, self.processed_img.shape[:2], self.target_disp_dims)\n",
    "        self.ref_mask = create_polygon_mask(self.ref_poly_points, self.ref_img.shape[:2], self.ref_disp_dims)\n",
    "        self.target_local_colors = extract_dominant_colors(self.processed_img, self.target_mask, n_colors=4)\n",
    "        self.ref_local_colors = extract_dominant_colors(self.ref_img, self.ref_mask, n_colors=4)\n",
    "        self.display_local_palettes()\n",
    "        self.mapping = {}\n",
    "        self.status_label.config(text=\"Local colors extracted. Click a target swatch then a reference swatch to map them.\")\n",
    "    \n",
    "    def display_local_palettes(self):\n",
    "        for widget in self.target_palette_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        for color in self.target_local_colors:\n",
    "            hex_color = f\"#{color[2]:02x}{color[1]:02x}{color[0]:02x}\"\n",
    "            lbl = tk.Label(self.target_palette_frame, bg=hex_color, width=4, height=2, relief=tk.RAISED, bd=2)\n",
    "            lbl.pack(side=tk.LEFT, padx=5)\n",
    "            lbl.bind(\"<Button-1>\", lambda e, col=color: self.on_target_color_select(col))\n",
    "        \n",
    "        for widget in self.ref_palette_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        for color in self.ref_local_colors:\n",
    "            hex_color = f\"#{color[2]:02x}{color[1]:02x}{color[0]:02x}\"\n",
    "            lbl = tk.Label(self.ref_palette_frame, bg=hex_color, width=4, height=2, relief=tk.RAISED, bd=2)\n",
    "            lbl.pack(side=tk.LEFT, padx=5)\n",
    "            lbl.bind(\"<Button-1>\", lambda e, col=color: self.on_ref_color_select(col))\n",
    "        \n",
    "        for widget in self.mapping_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "    \n",
    "    def on_target_color_select(self, color):\n",
    "        # Convert list to tuple for hashing.\n",
    "        self.temp_target_color = tuple(color)\n",
    "        self.status_label.config(text=f\"Selected target color: {self.temp_target_color}. Now select corresponding reference color.\")\n",
    "    \n",
    "    def on_ref_color_select(self, color):\n",
    "        if not hasattr(self, 'temp_target_color') or self.temp_target_color is None:\n",
    "            self.status_label.config(text=\"Select a target color first.\")\n",
    "            return\n",
    "        self.mapping[self.temp_target_color] = tuple(color)\n",
    "        # Display mapping.\n",
    "        for widget in self.mapping_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        mapping_text = f\"Mapping: {self.temp_target_color} -> {tuple(color)}\"\n",
    "        tk.Label(self.mapping_frame, text=mapping_text).pack()\n",
    "        self.status_label.config(text=f\"Mapping added: {self.temp_target_color} -> {tuple(color)}.\")\n",
    "        self.temp_target_color = None\n",
    "    \n",
    "    def apply_local_mapping(self):\n",
    "        if not self.mapping:\n",
    "            messagebox.showwarning(\"No Mapping\", \"Please map at least one color pair.\")\n",
    "            return\n",
    "        if self.target_mask is None:\n",
    "            messagebox.showerror(\"Error\", \"Local target mask not available.\")\n",
    "            return\n",
    "        new_img = apply_local_mapping(self.processed_img, self.target_mask, self.mapping, threshold=40)\n",
    "        self.processed_img = new_img\n",
    "        self.display_on_canvas(self.target_canvas, self.processed_img)\n",
    "        self.status_label.config(text=\"Local mapping applied.\")\n",
    "    \n",
    "    def display_on_canvas(self, canvas, cv_img):\n",
    "        photo = cv2_to_tk(cv_img, maxsize=(canvas.winfo_width(), canvas.winfo_height()))\n",
    "        canvas.photo = photo\n",
    "        canvas.delete(\"all\")\n",
    "        canvas.create_image(canvas.winfo_width()//2, canvas.winfo_height()//2, image=photo)\n",
    "    \n",
    "#############################################\n",
    "# Additional Functions\n",
    "#############################################\n",
    "\n",
    "def extract_dominant_colors(img, mask, n_colors=8):\n",
    "    pixels = img[mask].reshape(-1, 3)\n",
    "    if pixels.shape[0] < n_colors:\n",
    "        return []\n",
    "    kmeans = KMeans(n_clusters=n_colors, random_state=0)\n",
    "    kmeans.fit(pixels)\n",
    "    colors = kmeans.cluster_centers_.astype(np.uint8).tolist()\n",
    "    return colors\n",
    "\n",
    "#############################################\n",
    "# Main\n",
    "#############################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    def get_top_colors(image, k=10):\n",
    "        Z = image.reshape((-1, 3)).astype(np.float32)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(Z)\n",
    "        centers = kmeans.cluster_centers_.astype(np.uint8).tolist()\n",
    "        return centers\n",
    "    \n",
    "    app = InteractiveLocalMappingApp()\n",
    "    app.mainloop()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
